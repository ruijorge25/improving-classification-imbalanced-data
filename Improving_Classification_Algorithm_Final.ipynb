{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca4991cf",
   "metadata": {},
   "source": [
    "# **Improving Classification Algorithm for Difficult Data Conditions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55bf06c",
   "metadata": {},
   "source": [
    "In this assignment, we will be implementing a classification algorithm from scratch, analyze how a specific data issue affects its performance, propose a modification to improve it, and validate the results through empirical evaluation on benchmark datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0f06b",
   "metadata": {},
   "source": [
    "# 1st Step - Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "191ec064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pedro\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\pedro\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pedro\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\pedro\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\pedro\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: autograd in c:\\users\\pedro\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pedro\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\pedro\\anaconda3\\lib\\site-packages (5.9.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\pedro\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from nbformat) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from nbformat) (4.19.2)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from nbformat) (5.5.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from nbformat) (5.7.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\pedro\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat) (305.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn imbalanced-learn autograd tqdm nbformat plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0bf6cb",
   "metadata": {},
   "source": [
    "# 2nd Step - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e0baab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import io\n",
    "import shutil\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import logging\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f1bbb",
   "metadata": {},
   "source": [
    "# 3rd Step - Algorithm Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712cc5b",
   "metadata": {},
   "source": [
    "For this assignment we selected collectively to explore the Logistic Regression as our classification algorithm. We are going to use the standard version of the algorithm found on https://github.com/rushter/MLAlgorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e4c78",
   "metadata": {},
   "source": [
    "Logistic Regression models the probability of class membership by applying the sigmoid function to a linear combination of input features, enabling it to separate classes based on learned decision boundaries. It is sensitive to both noise and class imbalance, with a particular vulnerability to class imbalance, as it naturally biases toward the majority class during training. Although extensions allow logistic regression to handle multiclass problems, its performance is primarily affected by noise and imbalance rather than the multiclass setting itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67652d4",
   "metadata": {},
   "source": [
    "For this specific reason we are going to evaluate our algorithm on the Dataset Group 2: Class imbalance in binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59153280",
   "metadata": {},
   "source": [
    "# 4th Step - Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f477b3",
   "metadata": {},
   "source": [
    "For our algorithm to work as expected we need to make sure our data is clean and ready to be used, so we need to check the following cases:\n",
    "\n",
    " - Files categorical values on it;\n",
    " - Files with missing values.\n",
    "\n",
    "After we look up these files and fix them we also need to make sure that all our \"target\" classes have the same name, and after that we are going to attribute 1 to the minority classes and 0 to the majorities ones, to easier future comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b393f2",
   "metadata": {},
   "source": [
    "Let´s start by seeing how files have categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a922631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: dataset_1000_hypothyroid.csv\n",
      "   Shape: 3772 rows, 30 columns\n",
      "   Categorical features detected: ['sex', 'on thyroxine', 'query on thyroxine', 'on antithyroid medication', 'sick', 'pregnant', 'thyroid surgery', 'I131 treatment', 'query hypothyroid', 'query hyperthyroid', 'lithium', 'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH measured', 'T3 measured', 'TT4 measured', 'T4U measured', 'FTI measured', 'TBG measured', 'referral source']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.922853\n",
      "N    0.077147\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1002_ipums_la_98-small.csv\n",
      "   Shape: 7485 rows, 56 columns\n",
      "   Categorical features detected: ['gq', 'gqtypeg', 'farm', 'ownershg', 'relateg', 'sex', 'raceg', 'marst', 'chborn', 'school', 'educrec', 'schltype', 'empstatg', 'labforce', 'classwkg', 'wkswork2', 'hrswork2', 'workedyr', 'migrat5g', 'vetstat']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.894322\n",
      "N    0.105678\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1004_synthetic_control.csv\n",
      "   Shape: 600 rows, 61 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.833333\n",
      "P    0.166667\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1013_analcatdata_challenger.csv\n",
      "   Shape: 138 rows, 3 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'Damaged'\n",
      "\n",
      "Class distribution:\n",
      "Damaged\n",
      "0    0.934783\n",
      "1    0.065217\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1014_analcatdata_dmft.csv\n",
      "   Shape: 797 rows, 5 columns\n",
      "   Categorical features detected: ['Gender', 'Ethnic']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.805521\n",
      "P    0.194479\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1016_vowel.csv\n",
      "   Shape: 990 rows, 13 columns\n",
      "   Categorical features detected: ['Speaker Number', 'Sex']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.909091\n",
      "P    0.090909\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1018_ipums_la_99-small.csv\n",
      "   Shape: 8844 rows, 57 columns\n",
      "   Categorical features detected: ['gq', 'gqtypeg', 'farm', 'ownershg', 'relateg', 'sex', 'raceg', 'marst', 'chborn', 'school', 'educrec', 'schltype', 'empstatg', 'labforce', 'classwkg', 'wkswork2', 'hrswork2', 'yrlastwk', 'workedyr', 'migrat5g', 'vetstat']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.935776\n",
      "N    0.064224\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1020_mfeat-karhunen.csv\n",
      "   Shape: 2000 rows, 65 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.9\n",
      "P    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1021_page-blocks.csv\n",
      "   Shape: 5473 rows, 11 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.89768\n",
      "N    0.10232\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1022_mfeat-pixel.csv\n",
      "   Shape: 2000 rows, 241 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.9\n",
      "P    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1023_soybean.csv\n",
      "   Shape: 683 rows, 36 columns\n",
      "   Categorical features detected: ['date', 'plant-stand', 'precip', 'temp', 'hail', 'crop-hist', 'area-damaged', 'severity', 'seed-tmt', 'germination', 'plant-growth', 'leaves', 'leafspots-halo', 'leafspots-marg', 'leafspot-size', 'leaf-shread', 'leaf-malf', 'leaf-mild', 'stem', 'lodging', 'stem-cankers', 'canker-lesion', 'fruiting-bodies', 'external-decay', 'mycelium', 'int-discolor', 'sclerotia', 'fruit-pods', 'fruit-spots', 'seed', 'mold-growth', 'seed-discolor', 'seed-size', 'shriveling', 'roots']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.8653\n",
      "P    0.1347\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1039_hiva_agnostic.csv\n",
      "   Shape: 4229 rows, 1618 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'label'\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "-1    0.964767\n",
      " 1    0.035233\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1045_kc1-top5.csv\n",
      "   Shape: 145 rows, 95 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'DL'\n",
      "\n",
      "Class distribution:\n",
      "DL\n",
      "NODEF    0.944828\n",
      "DEF      0.055172\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1049_pc4.csv\n",
      "   Shape: 1458 rows, 38 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'c'\n",
      "\n",
      "Class distribution:\n",
      "c\n",
      "False    0.877915\n",
      "True     0.122085\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1050_pc3.csv\n",
      "   Shape: 1563 rows, 38 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'c'\n",
      "\n",
      "Class distribution:\n",
      "c\n",
      "False    0.897633\n",
      "True     0.102367\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1056_mc1.csv\n",
      "   Shape: 9466 rows, 39 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'c'\n",
      "\n",
      "Class distribution:\n",
      "c\n",
      "False    0.992816\n",
      "True     0.007184\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1059_ar1.csv\n",
      "   Shape: 121 rows, 30 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'defects'\n",
      "\n",
      "Class distribution:\n",
      "defects\n",
      "False    0.92562\n",
      "True     0.07438\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1061_ar4.csv\n",
      "   Shape: 107 rows, 30 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'defects'\n",
      "\n",
      "Class distribution:\n",
      "defects\n",
      "False    0.813084\n",
      "True     0.186916\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1064_ar6.csv\n",
      "   Shape: 101 rows, 30 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'defects'\n",
      "\n",
      "Class distribution:\n",
      "defects\n",
      "False    0.851485\n",
      "True     0.148515\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1065_kc3.csv\n",
      "   Shape: 458 rows, 40 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'c'\n",
      "\n",
      "Class distribution:\n",
      "c\n",
      "False    0.906114\n",
      "True     0.093886\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_311_oil_spill.csv\n",
      "   Shape: 937 rows, 50 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'class'\n",
      "\n",
      "Class distribution:\n",
      "class\n",
      "-1    0.956243\n",
      " 1    0.043757\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_312_scene.csv\n",
      "   Shape: 2407 rows, 300 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'Urban'\n",
      "\n",
      "Class distribution:\n",
      "Urban\n",
      "0    0.820939\n",
      "1    0.179061\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_316_yeast_ml8.csv\n",
      "   Shape: 2417 rows, 117 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'class14'\n",
      "\n",
      "Class distribution:\n",
      "class14\n",
      "0    0.985933\n",
      "1    0.014067\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_38_sick.csv\n",
      "   Shape: 3772 rows, 30 columns\n",
      "   Categorical features detected: ['sex', 'on_thyroxine', 'query_on_thyroxine', 'on_antithyroid_medication', 'sick', 'pregnant', 'thyroid_surgery', 'I131_treatment', 'query_hypothyroid', 'query_hyperthyroid', 'lithium', 'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH_measured', 'T3_measured', 'TT4_measured', 'T4U_measured', 'FTI_measured', 'TBG_measured', 'referral_source']\n",
      "   Target column: 'Class'\n",
      "\n",
      "Class distribution:\n",
      "Class\n",
      "negative    0.938759\n",
      "sick        0.061241\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_450_analcatdata_lawsuit.csv\n",
      "   Shape: 264 rows, 5 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'Laid.off'\n",
      "\n",
      "Class distribution:\n",
      "Laid.off\n",
      "0    0.92803\n",
      "1    0.07197\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_463_backache.csv\n",
      "   Shape: 180 rows, 32 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'col_33'\n",
      "\n",
      "Class distribution:\n",
      "col_33\n",
      "0    0.861111\n",
      "1    0.138889\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_757_meta.csv\n",
      "   Shape: 528 rows, 22 columns\n",
      "   Categorical features detected: ['DS_Name', 'Alg_Name']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.897727\n",
      "N    0.102273\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_764_analcatdata_apnea3.csv\n",
      "   Shape: 450 rows, 4 columns\n",
      "   Categorical features detected: ['Automatic', 'Scorer_2']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.877778\n",
      "N    0.122222\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_765_analcatdata_apnea2.csv\n",
      "   Shape: 475 rows, 4 columns\n",
      "   Categorical features detected: ['Automatic', 'Scorer_1']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.865263\n",
      "N    0.134737\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_767_analcatdata_apnea1.csv\n",
      "   Shape: 475 rows, 4 columns\n",
      "   Categorical features detected: ['Scorer_1', 'Scorer_2']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.871579\n",
      "N    0.128421\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_865_analcatdata_neavote.csv\n",
      "   Shape: 100 rows, 3 columns\n",
      "   Categorical features detected: ['Party']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.93\n",
      "P    0.07\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_867_visualizing_livestock.csv\n",
      "   Shape: 130 rows, 3 columns\n",
      "   Categorical features detected: ['livestocktype', 'country']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.807692\n",
      "N    0.192308\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_875_analcatdata_chlamydia.csv\n",
      "   Shape: 100 rows, 4 columns\n",
      "   Categorical features detected: ['Age', 'Gender', 'Race']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.81\n",
      "N    0.19\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_940_water-treatment.csv\n",
      "   Shape: 527 rows, 37 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.848197\n",
      "P    0.151803\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_947_arsenic-male-bladder.csv\n",
      "   Shape: 559 rows, 5 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.957066\n",
      "N    0.042934\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_949_arsenic-female-bladder.csv\n",
      "   Shape: 559 rows, 5 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.856887\n",
      "N    0.143113\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_950_arsenic-female-lung.csv\n",
      "   Shape: 559 rows, 5 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.966011\n",
      "N    0.033989\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_951_arsenic-male-lung.csv\n",
      "   Shape: 559 rows, 5 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.976744\n",
      "N    0.023256\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_954_spectrometer.csv\n",
      "   Shape: 531 rows, 102 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.896422\n",
      "P    0.103578\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_958_segment.csv\n",
      "   Shape: 2310 rows, 20 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.857143\n",
      "P    0.142857\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_962_mfeat-morphological.csv\n",
      "   Shape: 2000 rows, 7 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.9\n",
      "P    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_966_analcatdata_halloffame.csv\n",
      "   Shape: 1340 rows, 17 columns\n",
      "   Categorical features detected: ['Position']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "P    0.906716\n",
      "N    0.093284\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_968_analcatdata_birthday.csv\n",
      "   Shape: 365 rows, 4 columns\n",
      "   Categorical features detected: ['Month']\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.854795\n",
      "P    0.145205\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_971_mfeat-fourier.csv\n",
      "   Shape: 2000 rows, 77 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.9\n",
      "P    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_976_JapaneseVowels.csv\n",
      "   Shape: 9961 rows, 15 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.837968\n",
      "P    0.162032\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_978_mfeat-factors.csv\n",
      "   Shape: 2000 rows, 217 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.9\n",
      "P    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_980_optdigits.csv\n",
      "   Shape: 5620 rows, 65 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.898221\n",
      "P    0.101779\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_984_analcatdata_draft.csv\n",
      "   Shape: 366 rows, 5 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.912568\n",
      "P    0.087432\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_987_collins.csv\n",
      "   Shape: 500 rows, 23 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.84\n",
      "P    0.16\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_995_mfeat-zernike.csv\n",
      "   Shape: 2000 rows, 48 columns\n",
      "   No categorical features detected.\n",
      "   Target column: 'binaryClass'\n",
      "\n",
      "Class distribution:\n",
      "binaryClass\n",
      "N    0.9\n",
      "P    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Total files processed: 50\n",
      "Files with categorical features: 16\n"
     ]
    }
   ],
   "source": [
    "folder = \"class_imbalance\"\n",
    "\n",
    "total_files = 0\n",
    "files_with_categorical = 0\n",
    "files_with_categorical_list = []\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(folder, file))\n",
    "            total_files += 1\n",
    "\n",
    "            print(f\"\\nFile: {file}\")\n",
    "            print(f\"   Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "            # Check for categorical features\n",
    "            feature_cols = df.columns[:-1]  # exclude target\n",
    "            categorical_features = df[feature_cols].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "            if categorical_features:\n",
    "                print(f\"   Categorical features detected: {categorical_features}\")\n",
    "                files_with_categorical += 1\n",
    "                files_with_categorical_list.append(file)\n",
    "            else:\n",
    "                print(\"   No categorical features detected.\")\n",
    "\n",
    "            # Get the last column as the target\n",
    "            target_col = df.columns[-1]\n",
    "            print(f\"   Target column: '{target_col}'\")\n",
    "\n",
    "            # Print class distribution\n",
    "            print(\"\\nClass distribution:\")\n",
    "            print(df[target_col].value_counts(normalize=True))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with file {file}: {e}\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n\\nTotal files processed: {total_files}\")\n",
    "print(f\"Files with categorical features: {files_with_categorical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41201b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files with categorical features:\n",
      "- dataset_1000_hypothyroid.csv\n",
      "- dataset_1002_ipums_la_98-small.csv\n",
      "- dataset_1014_analcatdata_dmft.csv\n",
      "- dataset_1016_vowel.csv\n",
      "- dataset_1018_ipums_la_99-small.csv\n",
      "- dataset_1023_soybean.csv\n",
      "- dataset_38_sick.csv\n",
      "- dataset_757_meta.csv\n",
      "- dataset_764_analcatdata_apnea3.csv\n",
      "- dataset_765_analcatdata_apnea2.csv\n",
      "- dataset_767_analcatdata_apnea1.csv\n",
      "- dataset_865_analcatdata_neavote.csv\n",
      "- dataset_867_visualizing_livestock.csv\n",
      "- dataset_875_analcatdata_chlamydia.csv\n",
      "- dataset_966_analcatdata_halloffame.csv\n",
      "- dataset_968_analcatdata_birthday.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFiles with categorical features:\")\n",
    "for f in files_with_categorical_list:\n",
    "    print(f\"- {f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d4051",
   "metadata": {},
   "source": [
    "16 files with categorical values as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb609d",
   "metadata": {},
   "source": [
    "Now let's check for missing values, we are going to use common representations of missing values to garantee no mistake is made and to not let missing values go unseen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f48b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: dataset_1000_hypothyroid.csv\n",
      "Missing values:\n",
      "age       1\n",
      "sex     150\n",
      "TSH     369\n",
      "T3      769\n",
      "TT4     231\n",
      "T4U     387\n",
      "FTI     385\n",
      "TBG    3772\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_1002_ipums_la_98-small.csv\n",
      "Missing values:\n",
      "ownershg     132\n",
      "chborn      4424\n",
      "educrec      322\n",
      "schltype    5314\n",
      "empstatg    1811\n",
      "labforce    1811\n",
      "classwkg    3184\n",
      "wkswork2    3690\n",
      "hrswork2    4154\n",
      "workedyr    1811\n",
      "migrat5g    3954\n",
      "vetstat     1820\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_1004_synthetic_control.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1013_analcatdata_challenger.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1014_analcatdata_dmft.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1016_vowel.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1018_ipums_la_99-small.csv\n",
      "Missing values:\n",
      "ownershg     168\n",
      "chborn      5421\n",
      "school       428\n",
      "educrec      428\n",
      "schltype     428\n",
      "empstatg    2110\n",
      "labforce    2110\n",
      "classwkg    3671\n",
      "wkswork2    4198\n",
      "hrswork2    4782\n",
      "yrlastwk    6172\n",
      "workedyr    2110\n",
      "migrat5g     707\n",
      "vetstat     2110\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_1020_mfeat-karhunen.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1021_page-blocks.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1022_mfeat-pixel.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1023_soybean.csv\n",
      "Missing values:\n",
      "date                 1\n",
      "plant-stand         36\n",
      "precip              38\n",
      "temp                30\n",
      "hail               121\n",
      "crop-hist           16\n",
      "area-damaged         1\n",
      "severity           121\n",
      "seed-tmt           426\n",
      "germination        112\n",
      "plant-growth        16\n",
      "leafspots-halo      84\n",
      "leafspots-marg      84\n",
      "leafspot-size       84\n",
      "leaf-shread        100\n",
      "leaf-malf           84\n",
      "leaf-mild          108\n",
      "stem                16\n",
      "lodging            121\n",
      "stem-cankers        38\n",
      "canker-lesion       38\n",
      "fruiting-bodies    106\n",
      "external-decay      38\n",
      "mycelium            38\n",
      "int-discolor       619\n",
      "sclerotia           38\n",
      "fruit-pods          84\n",
      "fruit-spots        106\n",
      "seed                92\n",
      "mold-growth         92\n",
      "seed-discolor      106\n",
      "seed-size           92\n",
      "shriveling         106\n",
      "roots               31\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_1039_hiva_agnostic.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1045_kc1-top5.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1049_pc4.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1050_pc3.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1056_mc1.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1059_ar1.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1061_ar4.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1064_ar6.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1065_kc3.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_311_oil_spill.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_312_scene.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_316_yeast_ml8.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_38_sick.csv\n",
      "Missing values:\n",
      "age       1\n",
      "sex     150\n",
      "TSH     369\n",
      "T3      769\n",
      "TT4     231\n",
      "T4U     387\n",
      "FTI     385\n",
      "TBG    3772\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_450_analcatdata_lawsuit.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_463_backache.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_757_meta.csv\n",
      "Missing values:\n",
      "correl      24\n",
      "cancor2    240\n",
      "fract2     240\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_764_analcatdata_apnea3.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_765_analcatdata_apnea2.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_767_analcatdata_apnea1.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_865_analcatdata_neavote.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_867_visualizing_livestock.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_875_analcatdata_chlamydia.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_940_water-treatment.csv\n",
      "Missing values:\n",
      "ZN-E         3\n",
      "DBO-E       23\n",
      "DQO-E        6\n",
      "SS-E         1\n",
      "SSV-E       11\n",
      "SED-E       25\n",
      "DBO-P       40\n",
      "SSV-P       11\n",
      "SED-P       24\n",
      "DBO-D       28\n",
      "DQO-D        9\n",
      "SS-D         2\n",
      "SSV-D       13\n",
      "SED-D       25\n",
      "PH-S         1\n",
      "DBO-S       23\n",
      "DQO-S       18\n",
      "SS-S         5\n",
      "SSV-S       17\n",
      "SED-S       28\n",
      "COND-S       1\n",
      "RD-DBO-P    62\n",
      "RD-SS-P      4\n",
      "RD-SED-P    27\n",
      "RD-DBO-S    40\n",
      "RD-DQO-S    26\n",
      "RD-DBO-G    36\n",
      "RD-DQO-G    25\n",
      "RD-SS-G      8\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_947_arsenic-male-bladder.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_949_arsenic-female-bladder.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_950_arsenic-female-lung.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_951_arsenic-male-lung.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_954_spectrometer.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_958_segment.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_962_mfeat-morphological.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_966_analcatdata_halloffame.csv\n",
      "Missing values:\n",
      "Strikeouts    20\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_968_analcatdata_birthday.csv\n",
      "Missing values:\n",
      "Month    30\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_971_mfeat-fourier.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_976_JapaneseVowels.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_978_mfeat-factors.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_980_optdigits.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_984_analcatdata_draft.csv\n",
      "Missing values:\n",
      "Lottery.pick.1971    1\n",
      "dtype: int64\n",
      "\n",
      "File: dataset_987_collins.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_995_mfeat-zernike.csv\n",
      "No missing values.\n",
      "\n",
      "\n",
      "Total files with missing values: 10\n"
     ]
    }
   ],
   "source": [
    "folder = \"class_imbalance\"\n",
    "\n",
    "# Variable to track how many files have missing values\n",
    "files_with_missing_values = 0\n",
    "\n",
    "# Define common representations of missing values\n",
    "common_na = [\"\", \"NA\", \"NaN\", \"n/a\", \"N/A\", \"null\", \"NULL\", \"-\", \"--\", \"?\", \"none\", \"None\", \" \"]\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        try:\n",
    "            file_path = os.path.join(folder, file)\n",
    "\n",
    "            # Read CSV with common missing value representations\n",
    "            df = pd.read_csv(file_path, na_values=common_na)\n",
    "\n",
    "            print(f\"\\nFile: {file}\")\n",
    "\n",
    "            # Check for missing values\n",
    "            missing_values = df.isnull().sum()\n",
    "            if missing_values.sum() == 0:\n",
    "                print(\"No missing values.\")\n",
    "            else:\n",
    "                print(\"Missing values:\")\n",
    "                print(missing_values[missing_values > 0])\n",
    "                files_with_missing_values += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with file {file}: {e}\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n\\nTotal files with missing values: {files_with_missing_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10cff62",
   "metadata": {},
   "source": [
    "Now that we know we have 16 files with categorical features and 10 with missing values we are going to fix them!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fbf76",
   "metadata": {},
   "source": [
    "After a quick analysis we can see that some files have entire features with missing values, so we are going to remove them since they are useless for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97adf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output folders\n",
    "input_folder = \"class_imbalance\"\n",
    "cleaned_folder = \"class_imbalance_cleaned\"\n",
    "imputed_folder = \"class_imbalance_imputed\"\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "os.makedirs(cleaned_folder, exist_ok=True)\n",
    "os.makedirs(imputed_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af20bd8",
   "metadata": {},
   "source": [
    "Once our new folders are created we can move on to cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbae2dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: dataset_1000_hypothyroid.csv\n",
      "Removed columns: ['TBG']\n",
      "\n",
      "File: dataset_38_sick.csv\n",
      "Removed columns: ['TBG']\n",
      "\n",
      "\n",
      "Total files cleaned: 50\n"
     ]
    }
   ],
   "source": [
    "total_files_cleaned = 0\n",
    "\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        input_path = os.path.join(input_folder, file)\n",
    "        output_path = os.path.join(cleaned_folder, file)\n",
    "\n",
    "        try:\n",
    "            # Read CSV\n",
    "            df = pd.read_csv(input_path)\n",
    "            initial_columns = df.columns.tolist()\n",
    "\n",
    "            # Drop columns that are all NaN\n",
    "            df_cleaned = df.dropna(axis=1, how='all')\n",
    "            final_columns = df_cleaned.columns.tolist()\n",
    "\n",
    "            # Detect removed columns\n",
    "            removed_columns = list(set(initial_columns) - set(final_columns))\n",
    "\n",
    "            # Save cleaned file\n",
    "            df_cleaned.to_csv(output_path, index=False)\n",
    "            total_files_cleaned += 1\n",
    "\n",
    "            # Only print if some columns were removed\n",
    "            if removed_columns:\n",
    "                print(f\"\\nFile: {file}\")\n",
    "                print(f\"Removed columns: {removed_columns}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning {file}: {e}\")\n",
    "\n",
    "print(f\"\\n\\nTotal files cleaned: {total_files_cleaned}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f23c77",
   "metadata": {},
   "source": [
    "We can proceed to impute the missing values, we are doing so by using the mode for binary and categorical features and using the KNN for the remaining!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8192b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_binary(series):\n",
    "    \"\"\"Checks if a series is binary (ignoring NaNs).\"\"\"\n",
    "    unique_vals = series.dropna().astype(str).str.lower().unique()\n",
    "    return len(unique_vals) == 2\n",
    "\n",
    "def is_numeric(series):\n",
    "    \"\"\"Checks if a series is numeric.\"\"\"\n",
    "    try:\n",
    "        pd.to_numeric(series.dropna())\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def apply_smart_imputer(df):\n",
    "    \"\"\"Applies smart imputation: mode for binary/categorical, KNN for numeric.\"\"\"\n",
    "    feature_cols = df.columns[:-1]  # Last column is target\n",
    "    target_col = df.columns[-1]\n",
    "    \n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col]\n",
    "\n",
    "    binary_cols = []\n",
    "    categorical_cols = []\n",
    "    numeric_cols = []\n",
    "\n",
    "    for col in X.columns:\n",
    "        if is_binary(X[col]):\n",
    "            binary_cols.append(col)\n",
    "        elif not is_numeric(X[col]) or X[col].nunique() <= 10:\n",
    "            categorical_cols.append(col)\n",
    "        else:\n",
    "            numeric_cols.append(col)\n",
    "\n",
    "    print(f\"Imputing {len(binary_cols)} binary, {len(categorical_cols)} categorical, {len(numeric_cols)} numeric columns.\")\n",
    "\n",
    "    # Binary + Categorical: fill with mode\n",
    "    for col in binary_cols + categorical_cols:\n",
    "        if not X[col].mode().empty:\n",
    "            mode_val = X[col].mode()[0]\n",
    "            X[col] = X[col].fillna(mode_val)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' has no mode (all NaNs). Skipping.\")\n",
    "\n",
    "    # Numeric: KNN impute\n",
    "    valid_numeric = X[numeric_cols].dropna(axis=1, how='all')\n",
    "    removed = set(numeric_cols) - set(valid_numeric.columns)\n",
    "\n",
    "    if not valid_numeric.empty:\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        imputed_array = imputer.fit_transform(valid_numeric)\n",
    "        X[valid_numeric.columns] = imputed_array\n",
    "\n",
    "    if removed:\n",
    "        print(f\"Skipped all-NaN numeric columns: {removed}\")\n",
    "\n",
    "    # Return combined DataFrame with target\n",
    "    return pd.concat([X, y], axis=1)\n",
    "\n",
    "def validate_imputation(original_df, imputed_df):\n",
    "    \"\"\"Compare missing values before and after imputation.\"\"\"\n",
    "    feature_cols = original_df.columns[:-1]\n",
    "\n",
    "    before_missing = original_df[feature_cols].isnull().sum()\n",
    "    after_missing = imputed_df[feature_cols].isnull().sum()\n",
    "\n",
    "    still_missing = after_missing[after_missing > 0]\n",
    "\n",
    "    if still_missing.empty:\n",
    "        print(\"✅ Imputation successful: no missing values remain.\")\n",
    "    else:\n",
    "        print(\"⚠️ Some columns still have missing values:\")\n",
    "        print(still_missing)\n",
    "\n",
    "    # Optional: show change summary\n",
    "    total_before = before_missing.sum()\n",
    "    total_after = after_missing.sum()\n",
    "    print(f\"Missing before: {total_before} → after: {total_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "983d2509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing 20 binary, 2 categorical, 6 numeric columns.\n",
      "Imputed and saved: dataset_1000_hypothyroid.csv\n",
      "Imputing 8 binary, 29 categorical, 18 numeric columns.\n",
      "Imputed and saved: dataset_1002_ipums_la_98-small.csv\n",
      "Imputing 0 binary, 0 categorical, 60 numeric columns.\n",
      "Imputed and saved: dataset_1004_synthetic_control.csv\n",
      "Imputing 0 binary, 1 categorical, 1 numeric columns.\n",
      "Imputed and saved: dataset_1013_analcatdata_challenger.csv\n",
      "Imputing 1 binary, 3 categorical, 0 numeric columns.\n",
      "Imputed and saved: dataset_1014_analcatdata_dmft.csv\n",
      "Imputing 1 binary, 1 categorical, 10 numeric columns.\n",
      "Imputed and saved: dataset_1016_vowel.csv\n",
      "Imputing 9 binary, 28 categorical, 19 numeric columns.\n",
      "Imputed and saved: dataset_1018_ipums_la_99-small.csv\n",
      "Imputing 0 binary, 0 categorical, 64 numeric columns.\n",
      "Imputed and saved: dataset_1020_mfeat-karhunen.csv\n",
      "Imputing 0 binary, 0 categorical, 10 numeric columns.\n",
      "Imputed and saved: dataset_1021_page-blocks.csv\n",
      "Imputing 0 binary, 240 categorical, 0 numeric columns.\n",
      "Imputed and saved: dataset_1022_mfeat-pixel.csv\n",
      "Imputing 16 binary, 19 categorical, 0 numeric columns.\n",
      "Imputed and saved: dataset_1023_soybean.csv\n",
      "Imputing 1617 binary, 0 categorical, 0 numeric columns.\n",
      "Imputed and saved: dataset_1039_hiva_agnostic.csv\n",
      "Imputing 2 binary, 20 categorical, 72 numeric columns.\n",
      "Imputed and saved: dataset_1045_kc1-top5.csv\n",
      "Imputing 1 binary, 2 categorical, 34 numeric columns.\n",
      "Imputed and saved: dataset_1049_pc4.csv\n",
      "Imputing 0 binary, 1 categorical, 36 numeric columns.\n",
      "Imputed and saved: dataset_1050_pc3.csv\n",
      "Imputing 4 binary, 0 categorical, 34 numeric columns.\n",
      "Imputed and saved: dataset_1056_mc1.csv\n",
      "Imputing 0 binary, 4 categorical, 25 numeric columns.\n",
      "Imputed and saved: dataset_1059_ar1.csv\n",
      "Imputing 0 binary, 2 categorical, 27 numeric columns.\n",
      "Imputed and saved: dataset_1061_ar4.csv\n",
      "Imputing 0 binary, 4 categorical, 25 numeric columns.\n",
      "Imputed and saved: dataset_1064_ar6.csv\n",
      "Imputing 0 binary, 2 categorical, 37 numeric columns.\n",
      "Imputed and saved: dataset_1065_kc3.csv\n",
      "Imputing 1 binary, 9 categorical, 39 numeric columns.\n",
      "Imputed and saved: dataset_311_oil_spill.csv\n",
      "Imputing 5 binary, 0 categorical, 294 numeric columns.\n",
      "Imputed and saved: dataset_312_scene.csv\n",
      "Imputing 13 binary, 0 categorical, 103 numeric columns.\n",
      "Imputed and saved: dataset_316_yeast_ml8.csv\n",
      "Imputing 20 binary, 2 categorical, 6 numeric columns.\n",
      "Imputed and saved: dataset_38_sick.csv\n",
      "Imputing 1 binary, 0 categorical, 3 numeric columns.\n",
      "Imputed and saved: dataset_450_analcatdata_lawsuit.csv\n",
      "Imputing 22 binary, 4 categorical, 5 numeric columns.\n",
      "Imputed and saved: dataset_463_backache.csv\n",
      "Imputing 1 binary, 5 categorical, 15 numeric columns.\n",
      "Imputed and saved: dataset_757_meta.csv\n",
      "Imputing 0 binary, 2 categorical, 1 numeric columns.\n",
      "Imputed and saved: dataset_764_analcatdata_apnea3.csv\n",
      "Imputing 0 binary, 2 categorical, 1 numeric columns.\n",
      "Imputed and saved: dataset_765_analcatdata_apnea2.csv\n",
      "Imputing 0 binary, 2 categorical, 1 numeric columns.\n",
      "Imputed and saved: dataset_767_analcatdata_apnea1.csv\n",
      "Imputing 0 binary, 2 categorical, 0 numeric columns.\n",
      "Imputed and saved: dataset_865_analcatdata_neavote.csv\n",
      "Imputing 0 binary, 2 categorical, 0 numeric columns.\n",
      "Imputed and saved: dataset_867_visualizing_livestock.csv\n",
      "Imputing 1 binary, 2 categorical, 0 numeric columns.\n",
      "Imputed and saved: dataset_875_analcatdata_chlamydia.csv\n",
      "Imputing 0 binary, 0 categorical, 36 numeric columns.\n",
      "Imputed and saved: dataset_940_water-treatment.csv\n",
      "Imputing 0 binary, 0 categorical, 4 numeric columns.\n",
      "Imputed and saved: dataset_947_arsenic-male-bladder.csv\n",
      "Imputing 0 binary, 0 categorical, 4 numeric columns.\n",
      "Imputed and saved: dataset_949_arsenic-female-bladder.csv\n",
      "Imputing 0 binary, 0 categorical, 4 numeric columns.\n",
      "Imputed and saved: dataset_950_arsenic-female-lung.csv\n",
      "Imputing 0 binary, 0 categorical, 4 numeric columns.\n",
      "Imputed and saved: dataset_951_arsenic-male-lung.csv\n",
      "Imputing 0 binary, 2 categorical, 99 numeric columns.\n",
      "Imputed and saved: dataset_954_spectrometer.csv\n",
      "Imputing 0 binary, 3 categorical, 16 numeric columns.\n",
      "Imputed and saved: dataset_958_segment.csv\n",
      "Imputing 0 binary, 3 categorical, 3 numeric columns.\n",
      "Imputed and saved: dataset_962_mfeat-morphological.csv\n",
      "Imputing 0 binary, 1 categorical, 15 numeric columns.\n",
      "Imputed and saved: dataset_966_analcatdata_halloffame.csv\n",
      "Imputing 0 binary, 1 categorical, 2 numeric columns.\n",
      "Imputed and saved: dataset_968_analcatdata_birthday.csv\n",
      "Imputing 0 binary, 0 categorical, 76 numeric columns.\n",
      "Imputed and saved: dataset_971_mfeat-fourier.csv\n",
      "Imputing 0 binary, 0 categorical, 14 numeric columns.\n",
      "Imputed and saved: dataset_976_JapaneseVowels.csv\n",
      "Imputing 0 binary, 0 categorical, 216 numeric columns.\n",
      "Imputed and saved: dataset_978_mfeat-factors.csv\n",
      "Imputing 3 binary, 10 categorical, 51 numeric columns.\n",
      "Imputed and saved: dataset_980_optdigits.csv\n",
      "Imputing 0 binary, 0 categorical, 4 numeric columns.\n",
      "Imputed and saved: dataset_984_analcatdata_draft.csv\n",
      "Imputing 0 binary, 1 categorical, 21 numeric columns.\n",
      "Imputed and saved: dataset_987_collins.csv\n",
      "Imputing 0 binary, 0 categorical, 47 numeric columns.\n",
      "Imputed and saved: dataset_995_mfeat-zernike.csv\n",
      "\n",
      "Total files imputed: 50\n"
     ]
    }
   ],
   "source": [
    "#Process cleaned files with smart imputer\n",
    "\n",
    "total_files_imputed = 0\n",
    "\n",
    "for file in os.listdir(cleaned_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        input_path = os.path.join(cleaned_folder, file)\n",
    "        output_path = os.path.join(imputed_folder, file)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(input_path)\n",
    "            df_imputed = apply_smart_imputer(df)\n",
    "\n",
    "            df_imputed.to_csv(output_path, index=False)\n",
    "            total_files_imputed += 1\n",
    "\n",
    "            print(f\"Imputed and saved: {file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error imputing {file}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal files imputed: {total_files_imputed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f696b52",
   "metadata": {},
   "source": [
    "Let´s see if our code ran correctly checking again for missing values and manually see if the imputation was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b78f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: dataset_1000_hypothyroid.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1002_ipums_la_98-small.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1004_synthetic_control.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1013_analcatdata_challenger.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1014_analcatdata_dmft.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1016_vowel.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1018_ipums_la_99-small.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1020_mfeat-karhunen.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1021_page-blocks.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1022_mfeat-pixel.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1023_soybean.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1039_hiva_agnostic.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1045_kc1-top5.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1049_pc4.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1050_pc3.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1056_mc1.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1059_ar1.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1061_ar4.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1064_ar6.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_1065_kc3.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_311_oil_spill.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_312_scene.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_316_yeast_ml8.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_38_sick.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_450_analcatdata_lawsuit.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_463_backache.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_757_meta.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_764_analcatdata_apnea3.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_765_analcatdata_apnea2.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_767_analcatdata_apnea1.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_865_analcatdata_neavote.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_867_visualizing_livestock.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_875_analcatdata_chlamydia.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_940_water-treatment.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_947_arsenic-male-bladder.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_949_arsenic-female-bladder.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_950_arsenic-female-lung.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_951_arsenic-male-lung.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_954_spectrometer.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_958_segment.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_962_mfeat-morphological.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_966_analcatdata_halloffame.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_968_analcatdata_birthday.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_971_mfeat-fourier.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_976_JapaneseVowels.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_978_mfeat-factors.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_980_optdigits.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_984_analcatdata_draft.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_987_collins.csv\n",
      "No missing values.\n",
      "\n",
      "File: dataset_995_mfeat-zernike.csv\n",
      "No missing values.\n",
      "\n",
      "\n",
      "Total files with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Variable to track how many files have missing values\n",
    "files_with_missing_values = 0\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for file in os.listdir(imputed_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(imputed_folder, file))\n",
    "\n",
    "            print(f\"\\nFile: {file}\")\n",
    "\n",
    "            # Check for missing values\n",
    "            missing_values = df.isnull().sum()\n",
    "            if missing_values.sum() == 0:\n",
    "                print(\"No missing values.\")\n",
    "            else:\n",
    "                print(\"Missing values:\")\n",
    "                print(missing_values[missing_values > 0])\n",
    "                files_with_missing_values += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with file {file}: {e}\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n\\nTotal files with missing values: {files_with_missing_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed545ad",
   "metadata": {},
   "source": [
    "Now that we have none missing values we can use Label Encoder and One-Hot Encoder to verify that all our data is numerical. For simple categories like \"Yes/No\", we use Label Encoding (assigning 0 and 1). For multiple categories like colors, we apply One-Hot Encoding, creating separate columns with 1s and 0s to avoid false numerical relationships.\n",
    "\n",
    "We'll handle the target column separately later, ensuring the minority class is labeled as 1 and majority as 0 for clarity. These transformations give us clean, numerical data ready for machine learning models to process effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c12eb17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " One-Hot Encoded 'sex' (2 categorias)\n",
      " One-Hot Encoded 'on thyroxine' (2 categorias)\n",
      " One-Hot Encoded 'query on thyroxine' (2 categorias)\n",
      " One-Hot Encoded 'on antithyroid medication' (2 categorias)\n",
      " One-Hot Encoded 'sick' (2 categorias)\n",
      " One-Hot Encoded 'pregnant' (2 categorias)\n",
      " One-Hot Encoded 'thyroid surgery' (2 categorias)\n",
      " One-Hot Encoded 'I131 treatment' (2 categorias)\n",
      " One-Hot Encoded 'query hypothyroid' (2 categorias)\n",
      " One-Hot Encoded 'query hyperthyroid' (2 categorias)\n",
      " One-Hot Encoded 'lithium' (2 categorias)\n",
      " One-Hot Encoded 'goitre' (2 categorias)\n",
      " One-Hot Encoded 'tumor' (2 categorias)\n",
      " One-Hot Encoded 'hypopituitary' (2 categorias)\n",
      " One-Hot Encoded 'psych' (2 categorias)\n",
      " One-Hot Encoded 'TSH measured' (2 categorias)\n",
      " One-Hot Encoded 'T3 measured' (2 categorias)\n",
      " One-Hot Encoded 'TT4 measured' (2 categorias)\n",
      " One-Hot Encoded 'T4U measured' (2 categorias)\n",
      " One-Hot Encoded 'FTI measured' (2 categorias)\n",
      " One-Hot Encoded 'TBG measured' (1 categorias)\n",
      " One-Hot Encoded 'referral source' (5 categorias)\n",
      "Processed and saved: dataset_1000_hypothyroid.csv\n",
      "\n",
      " One-Hot Encoded 'gq' (3 categorias)\n",
      " One-Hot Encoded 'gqtypeg' (8 categorias)\n",
      " One-Hot Encoded 'farm' (2 categorias)\n",
      " One-Hot Encoded 'ownershg' (2 categorias)\n",
      " One-Hot Encoded 'relateg' (13 categorias)\n",
      " One-Hot Encoded 'sex' (2 categorias)\n",
      " One-Hot Encoded 'raceg' (7 categorias)\n",
      " One-Hot Encoded 'marst' (6 categorias)\n",
      " One-Hot Encoded 'chborn' (13 categorias)\n",
      " One-Hot Encoded 'school' (2 categorias)\n",
      " One-Hot Encoded 'educrec' (9 categorias)\n",
      " One-Hot Encoded 'schltype' (3 categorias)\n",
      " One-Hot Encoded 'empstatg' (3 categorias)\n",
      " One-Hot Encoded 'labforce' (2 categorias)\n",
      " One-Hot Encoded 'classwkg' (2 categorias)\n",
      " One-Hot Encoded 'wkswork2' (6 categorias)\n",
      " One-Hot Encoded 'hrswork2' (8 categorias)\n",
      " One-Hot Encoded 'workedyr' (2 categorias)\n",
      " One-Hot Encoded 'migrat5g' (5 categorias)\n",
      " One-Hot Encoded 'vetstat' (2 categorias)\n",
      "Processed and saved: dataset_1002_ipums_la_98-small.csv\n",
      "\n",
      "Processed and saved: dataset_1004_synthetic_control.csv\n",
      "\n",
      "Processed and saved: dataset_1013_analcatdata_challenger.csv\n",
      "\n",
      " One-Hot Encoded 'Gender' (2 categorias)\n",
      " One-Hot Encoded 'Ethnic' (3 categorias)\n",
      "Processed and saved: dataset_1014_analcatdata_dmft.csv\n",
      "\n",
      " One-Hot Encoded 'Speaker Number' (15 categorias)\n",
      " One-Hot Encoded 'Sex' (2 categorias)\n",
      "Processed and saved: dataset_1016_vowel.csv\n",
      "\n",
      " One-Hot Encoded 'gq' (3 categorias)\n",
      " One-Hot Encoded 'gqtypeg' (3 categorias)\n",
      " One-Hot Encoded 'farm' (2 categorias)\n",
      " One-Hot Encoded 'ownershg' (2 categorias)\n",
      " One-Hot Encoded 'relateg' (13 categorias)\n",
      " One-Hot Encoded 'sex' (2 categorias)\n",
      " One-Hot Encoded 'raceg' (7 categorias)\n",
      " One-Hot Encoded 'marst' (6 categorias)\n",
      " One-Hot Encoded 'chborn' (13 categorias)\n",
      " One-Hot Encoded 'school' (2 categorias)\n",
      " One-Hot Encoded 'educrec' (9 categorias)\n",
      " One-Hot Encoded 'schltype' (3 categorias)\n",
      " One-Hot Encoded 'empstatg' (3 categorias)\n",
      " One-Hot Encoded 'labforce' (2 categorias)\n",
      " One-Hot Encoded 'classwkg' (2 categorias)\n",
      " One-Hot Encoded 'wkswork2' (6 categorias)\n",
      " One-Hot Encoded 'hrswork2' (8 categorias)\n",
      " One-Hot Encoded 'yrlastwk' (7 categorias)\n",
      " One-Hot Encoded 'workedyr' (2 categorias)\n",
      " One-Hot Encoded 'migrat5g' (2 categorias)\n",
      " One-Hot Encoded 'vetstat' (2 categorias)\n",
      "Processed and saved: dataset_1018_ipums_la_99-small.csv\n",
      "\n",
      "Processed and saved: dataset_1020_mfeat-karhunen.csv\n",
      "\n",
      "Processed and saved: dataset_1021_page-blocks.csv\n",
      "\n",
      "Processed and saved: dataset_1022_mfeat-pixel.csv\n",
      "\n",
      " One-Hot Encoded 'date' (7 categorias)\n",
      " One-Hot Encoded 'plant-stand' (2 categorias)\n",
      " One-Hot Encoded 'precip' (3 categorias)\n",
      " One-Hot Encoded 'temp' (3 categorias)\n",
      " One-Hot Encoded 'hail' (2 categorias)\n",
      " One-Hot Encoded 'crop-hist' (4 categorias)\n",
      " One-Hot Encoded 'area-damaged' (4 categorias)\n",
      " One-Hot Encoded 'severity' (3 categorias)\n",
      " One-Hot Encoded 'seed-tmt' (3 categorias)\n",
      " One-Hot Encoded 'germination' (3 categorias)\n",
      " One-Hot Encoded 'plant-growth' (2 categorias)\n",
      " One-Hot Encoded 'leaves' (2 categorias)\n",
      " One-Hot Encoded 'leafspots-halo' (3 categorias)\n",
      " One-Hot Encoded 'leafspots-marg' (3 categorias)\n",
      " One-Hot Encoded 'leafspot-size' (3 categorias)\n",
      " One-Hot Encoded 'leaf-shread' (2 categorias)\n",
      " One-Hot Encoded 'leaf-malf' (2 categorias)\n",
      " One-Hot Encoded 'leaf-mild' (3 categorias)\n",
      " One-Hot Encoded 'stem' (2 categorias)\n",
      " One-Hot Encoded 'lodging' (2 categorias)\n",
      " One-Hot Encoded 'stem-cankers' (4 categorias)\n",
      " One-Hot Encoded 'canker-lesion' (4 categorias)\n",
      " One-Hot Encoded 'fruiting-bodies' (2 categorias)\n",
      " One-Hot Encoded 'external-decay' (3 categorias)\n",
      " One-Hot Encoded 'mycelium' (2 categorias)\n",
      " One-Hot Encoded 'int-discolor' (3 categorias)\n",
      " One-Hot Encoded 'sclerotia' (2 categorias)\n",
      " One-Hot Encoded 'fruit-pods' (4 categorias)\n",
      " One-Hot Encoded 'fruit-spots' (4 categorias)\n",
      " One-Hot Encoded 'seed' (2 categorias)\n",
      " One-Hot Encoded 'mold-growth' (2 categorias)\n",
      " One-Hot Encoded 'seed-discolor' (2 categorias)\n",
      " One-Hot Encoded 'seed-size' (2 categorias)\n",
      " One-Hot Encoded 'shriveling' (2 categorias)\n",
      " One-Hot Encoded 'roots' (3 categorias)\n",
      "Processed and saved: dataset_1023_soybean.csv\n",
      "\n",
      "Processed and saved: dataset_1039_hiva_agnostic.csv\n",
      "\n",
      "Processed and saved: dataset_1045_kc1-top5.csv\n",
      "\n",
      "Processed and saved: dataset_1049_pc4.csv\n",
      "\n",
      "Processed and saved: dataset_1050_pc3.csv\n",
      "\n",
      "Processed and saved: dataset_1056_mc1.csv\n",
      "\n",
      "Processed and saved: dataset_1059_ar1.csv\n",
      "\n",
      "Processed and saved: dataset_1061_ar4.csv\n",
      "\n",
      "Processed and saved: dataset_1064_ar6.csv\n",
      "\n",
      "Processed and saved: dataset_1065_kc3.csv\n",
      "\n",
      "Processed and saved: dataset_311_oil_spill.csv\n",
      "\n",
      "Processed and saved: dataset_312_scene.csv\n",
      "\n",
      "Processed and saved: dataset_316_yeast_ml8.csv\n",
      "\n",
      " One-Hot Encoded 'sex' (2 categorias)\n",
      " One-Hot Encoded 'on_thyroxine' (2 categorias)\n",
      " One-Hot Encoded 'query_on_thyroxine' (2 categorias)\n",
      " One-Hot Encoded 'on_antithyroid_medication' (2 categorias)\n",
      " One-Hot Encoded 'sick' (2 categorias)\n",
      " One-Hot Encoded 'pregnant' (2 categorias)\n",
      " One-Hot Encoded 'thyroid_surgery' (2 categorias)\n",
      " One-Hot Encoded 'I131_treatment' (2 categorias)\n",
      " One-Hot Encoded 'query_hypothyroid' (2 categorias)\n",
      " One-Hot Encoded 'query_hyperthyroid' (2 categorias)\n",
      " One-Hot Encoded 'lithium' (2 categorias)\n",
      " One-Hot Encoded 'goitre' (2 categorias)\n",
      " One-Hot Encoded 'tumor' (2 categorias)\n",
      " One-Hot Encoded 'hypopituitary' (2 categorias)\n",
      " One-Hot Encoded 'psych' (2 categorias)\n",
      " One-Hot Encoded 'TSH_measured' (2 categorias)\n",
      " One-Hot Encoded 'T3_measured' (2 categorias)\n",
      " One-Hot Encoded 'TT4_measured' (2 categorias)\n",
      " One-Hot Encoded 'T4U_measured' (2 categorias)\n",
      " One-Hot Encoded 'FTI_measured' (2 categorias)\n",
      " One-Hot Encoded 'TBG_measured' (1 categorias)\n",
      " One-Hot Encoded 'referral_source' (5 categorias)\n",
      "Processed and saved: dataset_38_sick.csv\n",
      "\n",
      "Processed and saved: dataset_450_analcatdata_lawsuit.csv\n",
      "\n",
      "Processed and saved: dataset_463_backache.csv\n",
      "\n",
      " Label Encoded 'DS_Name' (22 categorias)\n",
      " Label Encoded 'Alg_Name' (24 categorias)\n",
      "Processed and saved: dataset_757_meta.csv\n",
      "\n",
      " One-Hot Encoded 'Automatic' (5 categorias)\n",
      " One-Hot Encoded 'Scorer_2' (5 categorias)\n",
      "Processed and saved: dataset_764_analcatdata_apnea3.csv\n",
      "\n",
      " One-Hot Encoded 'Automatic' (5 categorias)\n",
      " One-Hot Encoded 'Scorer_1' (5 categorias)\n",
      "Processed and saved: dataset_765_analcatdata_apnea2.csv\n",
      "\n",
      " One-Hot Encoded 'Scorer_1' (5 categorias)\n",
      " One-Hot Encoded 'Scorer_2' (5 categorias)\n",
      "Processed and saved: dataset_767_analcatdata_apnea1.csv\n",
      "\n",
      " One-Hot Encoded 'Party' (3 categorias)\n",
      "Processed and saved: dataset_865_analcatdata_neavote.csv\n",
      "\n",
      " One-Hot Encoded 'livestocktype' (5 categorias)\n",
      " Label Encoded 'country' (26 categorias)\n",
      "Processed and saved: dataset_867_visualizing_livestock.csv\n",
      "\n",
      " One-Hot Encoded 'Age' (10 categorias)\n",
      " One-Hot Encoded 'Gender' (2 categorias)\n",
      " One-Hot Encoded 'Race' (5 categorias)\n",
      "Processed and saved: dataset_875_analcatdata_chlamydia.csv\n",
      "\n",
      "Processed and saved: dataset_940_water-treatment.csv\n",
      "\n",
      "Processed and saved: dataset_947_arsenic-male-bladder.csv\n",
      "\n",
      "Processed and saved: dataset_949_arsenic-female-bladder.csv\n",
      "\n",
      "Processed and saved: dataset_950_arsenic-female-lung.csv\n",
      "\n",
      "Processed and saved: dataset_951_arsenic-male-lung.csv\n",
      "\n",
      "Processed and saved: dataset_954_spectrometer.csv\n",
      "\n",
      "Processed and saved: dataset_958_segment.csv\n",
      "\n",
      "Processed and saved: dataset_962_mfeat-morphological.csv\n",
      "\n",
      " One-Hot Encoded 'Position' (7 categorias)\n",
      "Processed and saved: dataset_966_analcatdata_halloffame.csv\n",
      "\n",
      " One-Hot Encoded 'Month' (11 categorias)\n",
      "Processed and saved: dataset_968_analcatdata_birthday.csv\n",
      "\n",
      "Processed and saved: dataset_971_mfeat-fourier.csv\n",
      "\n",
      "Processed and saved: dataset_976_JapaneseVowels.csv\n",
      "\n",
      "Processed and saved: dataset_978_mfeat-factors.csv\n",
      "\n",
      "Processed and saved: dataset_980_optdigits.csv\n",
      "\n",
      "Processed and saved: dataset_984_analcatdata_draft.csv\n",
      "\n",
      "Processed and saved: dataset_987_collins.csv\n",
      "\n",
      "Processed and saved: dataset_995_mfeat-zernike.csv\n",
      "\n",
      "\n",
      "All files processed! Report saved to 'encoding_report.txt'\n",
      "\n",
      "Total datasets processed with encoders (OHE or Label Encoding): 16\n"
     ]
    }
   ],
   "source": [
    "def encode_features(df, ohe_threshold):\n",
    "    feature_cols = df.columns[:-1]  # Para não tocar na coluna target\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "    categorical_features = df[feature_cols].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if not categorical_features:\n",
    "        return df, [], []\n",
    "\n",
    "    df_encoded = df.copy()\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    ohe_cols = []\n",
    "    label_cols = []\n",
    "\n",
    "    for col in categorical_features:\n",
    "        unique_values = df_encoded[col].nunique()\n",
    "\n",
    "        if unique_values <= ohe_threshold:\n",
    "            # One-Hot Encoder\n",
    "            ohe_df = pd.DataFrame(\n",
    "                ohe.fit_transform(df_encoded[[col]]),\n",
    "                columns=[f\"{col}{cat}\" for cat in ohe.categories_[0]],\n",
    "                index=df_encoded.index\n",
    "            )\n",
    "            df_encoded = pd.concat([df_encoded.drop(columns=[col]), ohe_df], axis=1)\n",
    "            print(f\" One-Hot Encoded '{col}' ({unique_values} categorias)\")\n",
    "            ohe_cols.append(col)\n",
    "        else:\n",
    "            # Label Encoder\n",
    "            df_encoded[col] = pd.factorize(df_encoded[col])[0]\n",
    "            print(f\" Label Encoded '{col}' ({unique_values} categorias)\")\n",
    "            label_cols.append(col)\n",
    "\n",
    "    # Manter target no fim\n",
    "    cols = [col for col in df_encoded.columns if col != target_col] + [target_col]\n",
    "    df_encoded = df_encoded[cols]\n",
    "\n",
    "    return df_encoded, ohe_cols, label_cols\n",
    "\n",
    "def process_files(original_folder, modified_folder, ohe_threshold):\n",
    "    os.makedirs(modified_folder, exist_ok=True)\n",
    "    report_lines = []\n",
    "    \n",
    "    datasets_with_encoders = 0  # Contador para datasets que utilizaram o encoder\n",
    "\n",
    "    for file in os.listdir(original_folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            original_path = os.path.join(original_folder, file)\n",
    "            modified_path = os.path.join(modified_folder, file)\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(original_path)\n",
    "                df_encoded, ohe_cols, label_cols = encode_features(df, ohe_threshold)\n",
    "\n",
    "                df_encoded.to_csv(modified_path, index=False)\n",
    "                print(f\"Processed and saved: {file}\\n\")\n",
    "\n",
    "                # Verificar se o dataset utilizou algum encoder\n",
    "                if ohe_cols or label_cols:\n",
    "                    datasets_with_encoders += 1  # Incrementar se houver uso de encoder\n",
    "                \n",
    "                report_lines.append(f\"File: {file}\")\n",
    "                if ohe_cols:\n",
    "                    report_lines.append(f\"  One-Hot Encoded columns: {', '.join(ohe_cols)}\")\n",
    "                if label_cols:\n",
    "                    report_lines.append(f\"  Label Encoded columns: {', '.join(label_cols)}\")\n",
    "                if not ohe_cols and not label_cols:\n",
    "                    report_lines.append(\"  No categorical columns detected.\")\n",
    "                report_lines.append(\"\")  # linha em branco entre ficheiros\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\\n\")\n",
    "                report_lines.append(f\"Error processing {file}: {e}\")\n",
    "                report_lines.append(\"\")\n",
    "\n",
    "    # Guardar relatório\n",
    "    report_path = os.path.join(modified_folder, \"encoding_report.txt\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(report_lines))\n",
    "\n",
    "    print(\"\\nAll files processed! Report saved to 'encoding_report.txt'\")\n",
    "\n",
    "    # Imprimir o número de datasets que utilizaram o encoder\n",
    "    print(f\"\\nTotal datasets processed with encoders (OHE or Label Encoding): {datasets_with_encoders}\")\n",
    "    return datasets_with_encoders\n",
    "\n",
    "\n",
    "# Parâmetros de execução\n",
    "original_folder = \"class_imbalance_imputed\"\n",
    "modified_folder = \"class_imbalance_modified\"\n",
    "ohe_threshold = 15\n",
    "\n",
    "# Chamada da função para processar os arquivos\n",
    "datasets_with_encoders = process_files(original_folder, modified_folder, ohe_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdfbad",
   "metadata": {},
   "source": [
    "We can see that the total datasets processed with encoders were 16, the same number of datasets with categorical values in them! Also, we have the report saved in the folder to check manually if everything went as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaef14d",
   "metadata": {},
   "source": [
    "Now that we have a folder with all the data cleaned we just need to do the last step, name the last column of all datasets as \"target\" and make sure the minority class is 1 and 0 the majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63d5c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output folders\n",
    "input_folder = \"class_imbalance_modified\"             \n",
    "output_folder = \"class_imbalance_final\"      \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each CSV file in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if not filename.lower().endswith(\".csv\"):\n",
    "        continue  # skip non-CSV files\n",
    "    \n",
    "    # Read the dataset\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Rename the last column to 'target'\n",
    "    df.rename(columns={df.columns[-1]: \"target\"}, inplace=True)\n",
    "    \n",
    "    # Only handle binary classification cases\n",
    "    counts = df['target'].value_counts()\n",
    "    if len(counts) != 2:\n",
    "        # Skip files that are not binary\n",
    "        print(f\"Skipping {filename}: not binary classification.\")\n",
    "        continue\n",
    "    \n",
    "    # Identify majority and minority class labels\n",
    "    minority_label = counts.idxmin()  # label with fewer instances\n",
    "    majority_label = counts.idxmax()  # label with more instances\n",
    "    \n",
    "    # Map the minority class to 1 and the majority class to 0\n",
    "    df['target'] = df['target'].apply(lambda x: 1 if x == minority_label else 0)\n",
    "    \n",
    "    # Save the modified dataset to the new folder\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "    df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ddaeb",
   "metadata": {},
   "source": [
    "Let's check if everything is right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "816d2c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: dataset_1000_hypothyroid.csv\n",
      "   Shape: 3772 rows, 53 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.922853\n",
      "1    0.077147\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1002_ipums_la_98-small.csv\n",
      "   Shape: 7485 rows, 136 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.894322\n",
      "1    0.105678\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1004_synthetic_control.csv\n",
      "   Shape: 600 rows, 61 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.833333\n",
      "1    0.166667\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1013_analcatdata_challenger.csv\n",
      "   Shape: 138 rows, 3 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.934783\n",
      "1    0.065217\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1014_analcatdata_dmft.csv\n",
      "   Shape: 797 rows, 8 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.805521\n",
      "1    0.194479\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1016_vowel.csv\n",
      "   Shape: 990 rows, 28 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.909091\n",
      "1    0.090909\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1018_ipums_la_99-small.csv\n",
      "   Shape: 8844 rows, 135 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.935776\n",
      "1    0.064224\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1020_mfeat-karhunen.csv\n",
      "   Shape: 2000 rows, 65 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.9\n",
      "1    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1021_page-blocks.csv\n",
      "   Shape: 5473 rows, 11 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.89768\n",
      "1    0.10232\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1022_mfeat-pixel.csv\n",
      "   Shape: 2000 rows, 241 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.9\n",
      "1    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1023_soybean.csv\n",
      "   Shape: 683 rows, 100 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.8653\n",
      "1    0.1347\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1039_hiva_agnostic.csv\n",
      "   Shape: 4229 rows, 1618 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.964767\n",
      "1    0.035233\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1045_kc1-top5.csv\n",
      "   Shape: 145 rows, 95 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.944828\n",
      "1    0.055172\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1049_pc4.csv\n",
      "   Shape: 1458 rows, 38 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.877915\n",
      "1    0.122085\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1050_pc3.csv\n",
      "   Shape: 1563 rows, 38 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.897633\n",
      "1    0.102367\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1056_mc1.csv\n",
      "   Shape: 9466 rows, 39 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.992816\n",
      "1    0.007184\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1059_ar1.csv\n",
      "   Shape: 121 rows, 30 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.92562\n",
      "1    0.07438\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1061_ar4.csv\n",
      "   Shape: 107 rows, 30 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.813084\n",
      "1    0.186916\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1064_ar6.csv\n",
      "   Shape: 101 rows, 30 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.851485\n",
      "1    0.148515\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_1065_kc3.csv\n",
      "   Shape: 458 rows, 40 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.906114\n",
      "1    0.093886\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_311_oil_spill.csv\n",
      "   Shape: 937 rows, 50 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.956243\n",
      "1    0.043757\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_312_scene.csv\n",
      "   Shape: 2407 rows, 300 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.820939\n",
      "1    0.179061\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_316_yeast_ml8.csv\n",
      "   Shape: 2417 rows, 117 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.985933\n",
      "1    0.014067\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_38_sick.csv\n",
      "   Shape: 3772 rows, 53 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.938759\n",
      "1    0.061241\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_450_analcatdata_lawsuit.csv\n",
      "   Shape: 264 rows, 5 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.92803\n",
      "1    0.07197\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_463_backache.csv\n",
      "   Shape: 180 rows, 32 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.861111\n",
      "1    0.138889\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_757_meta.csv\n",
      "   Shape: 528 rows, 22 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.897727\n",
      "1    0.102273\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_764_analcatdata_apnea3.csv\n",
      "   Shape: 450 rows, 12 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.877778\n",
      "1    0.122222\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_765_analcatdata_apnea2.csv\n",
      "   Shape: 475 rows, 12 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.865263\n",
      "1    0.134737\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_767_analcatdata_apnea1.csv\n",
      "   Shape: 475 rows, 12 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.871579\n",
      "1    0.128421\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_865_analcatdata_neavote.csv\n",
      "   Shape: 100 rows, 5 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.93\n",
      "1    0.07\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_867_visualizing_livestock.csv\n",
      "   Shape: 130 rows, 7 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.807692\n",
      "1    0.192308\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_875_analcatdata_chlamydia.csv\n",
      "   Shape: 100 rows, 18 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.81\n",
      "1    0.19\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_940_water-treatment.csv\n",
      "   Shape: 527 rows, 37 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.848197\n",
      "1    0.151803\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_947_arsenic-male-bladder.csv\n",
      "   Shape: 559 rows, 5 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.957066\n",
      "1    0.042934\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_949_arsenic-female-bladder.csv\n",
      "   Shape: 559 rows, 5 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.856887\n",
      "1    0.143113\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_950_arsenic-female-lung.csv\n",
      "   Shape: 559 rows, 5 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.966011\n",
      "1    0.033989\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_951_arsenic-male-lung.csv\n",
      "   Shape: 559 rows, 5 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.976744\n",
      "1    0.023256\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_954_spectrometer.csv\n",
      "   Shape: 531 rows, 102 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.896422\n",
      "1    0.103578\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_958_segment.csv\n",
      "   Shape: 2310 rows, 20 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.857143\n",
      "1    0.142857\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_962_mfeat-morphological.csv\n",
      "   Shape: 2000 rows, 7 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.9\n",
      "1    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_966_analcatdata_halloffame.csv\n",
      "   Shape: 1340 rows, 23 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.906716\n",
      "1    0.093284\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_968_analcatdata_birthday.csv\n",
      "   Shape: 365 rows, 14 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.854795\n",
      "1    0.145205\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_971_mfeat-fourier.csv\n",
      "   Shape: 2000 rows, 77 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.9\n",
      "1    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_976_JapaneseVowels.csv\n",
      "   Shape: 9961 rows, 15 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.837968\n",
      "1    0.162032\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_978_mfeat-factors.csv\n",
      "   Shape: 2000 rows, 217 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.9\n",
      "1    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_980_optdigits.csv\n",
      "   Shape: 5620 rows, 65 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.898221\n",
      "1    0.101779\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_984_analcatdata_draft.csv\n",
      "   Shape: 366 rows, 5 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.912568\n",
      "1    0.087432\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_987_collins.csv\n",
      "   Shape: 500 rows, 23 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.84\n",
      "1    0.16\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "File: dataset_995_mfeat-zernike.csv\n",
      "   Shape: 2000 rows, 48 columns\n",
      "   Target column: 'target'\n",
      "   Class distribution:\n",
      "target\n",
      "0    0.9\n",
      "1    0.1\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Files with categorical features: 0\n",
      "Files with missing values: 0\n",
      "Total files processed: 50\n"
     ]
    }
   ],
   "source": [
    "folder = \"class_imbalance_final\"\n",
    "\n",
    "total_files = 0\n",
    "files_with_categorical = []\n",
    "files_with_missing = []\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if not file.lower().endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(os.path.join(folder, file))\n",
    "    total_files += 1\n",
    "\n",
    "    print(f\"\\nFile: {file}\")\n",
    "    print(f\"   Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "    # Record files that have any categorical features\n",
    "    feature_cols = df.columns[:-1]\n",
    "    if df[feature_cols].select_dtypes(include=['object', 'category']).any().any():\n",
    "        files_with_categorical.append(file)\n",
    "\n",
    "    # Record files that have any missing values\n",
    "    if df.isnull().any().any():\n",
    "        files_with_missing.append(file)\n",
    "\n",
    "    # Show target info\n",
    "    target_col = df.columns[-1]\n",
    "    print(f\"   Target column: '{target_col}'\")\n",
    "    print(\"   Class distribution:\")\n",
    "    print(df[target_col].value_counts(normalize=True))\n",
    "\n",
    "# Final summary counts\n",
    "print(f\"\\nFiles with categorical features: {len(files_with_categorical)}\")\n",
    "print(f\"Files with missing values: {len(files_with_missing)}\")\n",
    "print(f\"Total files processed: {total_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45308d8",
   "metadata": {},
   "source": [
    "Now we are reading to start our real work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0abc1",
   "metadata": {},
   "source": [
    "# 5th Step - Model Training & Evaluation: Pre‑Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d9bb1",
   "metadata": {},
   "source": [
    "Now that we have our data ready we can start the model training and evaluation on our base model! Firstly let's define our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efe72136",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "\n",
    "\n",
    "def binary_crossentropy(y_true, y_pred):\n",
    "    eps = 1e-8  # to avoid log(0)\n",
    "    return -np.mean(y_true * np.log(y_pred + eps) + (1 - y_true) * np.log(1 - y_pred + eps))\n",
    "\n",
    "\n",
    "class BasicRegression:\n",
    "    def __init__(self, lr=0.001, penalty=None, C=0.01, tolerance=1e-4, max_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.penalty = penalty\n",
    "        self.C = C\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iters = max_iters\n",
    "        self.errors = []\n",
    "        self.theta = None\n",
    "        self.n_samples, self.n_features = None, None\n",
    "        self.cost_func = None\n",
    "\n",
    "    def _add_penalty(self, loss, w):\n",
    "        if self.penalty == \"l1\":\n",
    "            loss += self.C * np.abs(w[1:]).sum()\n",
    "        elif self.penalty == \"l2\":\n",
    "            loss += 0.5 * self.C * (w[1:] ** 2).sum()\n",
    "        return loss\n",
    "\n",
    "    def _cost(self, X, y, theta):\n",
    "        prediction = X.dot(theta)\n",
    "        error = self.cost_func(y, prediction)\n",
    "        return error\n",
    "\n",
    "    def _add_intercept(self, X):\n",
    "        b = np.ones([X.shape[0], 1])\n",
    "        return np.concatenate([b, X], axis=1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).reshape(-1)\n",
    "\n",
    "        self.X = self._add_intercept(X)\n",
    "        self.y = y\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        self.init_cost()\n",
    "\n",
    "        self.theta = np.random.normal(size=(self.n_features + 1), scale=0.5)\n",
    "        self.theta, self.errors = self._gradient_descent()\n",
    "\n",
    "        logging.info(f\"Training completed. Final loss: {self.errors[-1]}\")\n",
    "\n",
    "    def _gradient_descent(self):\n",
    "        theta = self.theta\n",
    "        errors = [self._cost(self.X, self.y, theta)]\n",
    "        cost_d = grad(self._loss)\n",
    "\n",
    "        for i in range(1, self.max_iters + 1):\n",
    "            delta = cost_d(theta)\n",
    "            theta -= self.lr * delta\n",
    "\n",
    "            current_error = self._cost(self.X, self.y, theta)\n",
    "            errors.append(current_error)\n",
    "\n",
    "            logging.info(f\"Iteration {i}, error {current_error}\")\n",
    "\n",
    "            if np.abs(errors[-2] - errors[-1]) < self.tolerance:\n",
    "                logging.info(\"Convergence has reached.\")\n",
    "                break\n",
    "\n",
    "        return theta, errors\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        probs = self.predict_proba(X)\n",
    "        return (probs >= threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        raise NotImplementedError(\"This method should be implemented in a subclass.\")\n",
    "\n",
    "    def _loss(self, w):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def init_cost(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class LogisticRegression(BasicRegression):\n",
    "    def init_cost(self):\n",
    "        self.cost_func = binary_crossentropy\n",
    "\n",
    "    def _loss(self, w):\n",
    "        predictions = self.sigmoid(np.dot(self.X, w))\n",
    "\n",
    "        # Clamp predictions to avoid log(0)\n",
    "        eps = 1e-8\n",
    "        predictions = np.clip(predictions, eps, 1 - eps)\n",
    "\n",
    "        loss = self.cost_func(self.y, predictions)\n",
    "        return self._add_penalty(loss, w)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 0.5 * (np.tanh(0.5 * x) + 1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        X = self._add_intercept(X)\n",
    "        return self.sigmoid(np.dot(X, self.theta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a73122",
   "metadata": {},
   "source": [
    "We now are going to train our model and evaluate it but for that we need to standardize features, we are going to do that using StandardScaler. To garantee a fair training we are also going to make sure both classes appear in both training and testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e105e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data and Initialize Structures\n",
    "\n",
    "data_folder = \"class_imbalance_final\"\n",
    "csv_files = sorted(glob.glob(os.path.join(data_folder, \"*.csv\")))\n",
    "\n",
    "# Lists to accumulate results\n",
    "results = []  # Will hold dicts of metrics for each dataset\n",
    "roc_images = []  # Will hold (dataset_name, base64_png, auc) for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e408638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94b2150f2174c65a810c08ca2fed941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n",
      "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Process Each Dataset\n",
    "# For each CSV:\n",
    "# 1. Read data into X (features) and y (binary target).\n",
    "# 2. Repeatedly split (stratified) until both classes present in train and test.\n",
    "# 3. Scale features with StandardScaler (fit on train, transform both).\n",
    "# 4. Train logistic regression.\n",
    "# 5. Compute metrics on test set.\n",
    "# 6. Plot and save ROC curve for this dataset.\n",
    "\n",
    "for file_path in tqdm(csv_files, desc=\"Datasets\"):\n",
    "    dataset_name = os.path.basename(file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'target' not in df.columns:\n",
    "        # If not labeled, rename last col to 'target'\n",
    "        df = df.rename(columns={df.columns[-1]: 'target'})\n",
    "    X = df.drop(columns=['target']).values\n",
    "    y = df['target'].values\n",
    "\n",
    "    # Stratified split with retries to ensure both classes in train and test\n",
    "    seed = 0\n",
    "    while True:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, stratify=y, random_state=seed\n",
    "        )\n",
    "        # Check class presence\n",
    "        if len(np.unique(y_train)) == 2 and len(np.unique(y_test)) == 2:\n",
    "            break\n",
    "        seed += 1\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Model training\n",
    "    model = LogisticRegression()  # using default parameters\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]  # probability of class 1\n",
    "    except:\n",
    "        # Some implementations might use a different method name\n",
    "        y_proba = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'ROC AUC': auc\n",
    "    })\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "    plt.title(f'ROC Curve: {dataset_name}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot to base64\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    roc_images.append((dataset_name, img_base64, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3ff30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Metrics and Compute Averages\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "# Round metrics for display\n",
    "metrics_df[['Accuracy','Precision','Recall','F1-Score','ROC AUC']] = metrics_df[\n",
    "    ['Accuracy','Precision','Recall','F1-Score','ROC AUC']].round(3)\n",
    "\n",
    "# Compute average metrics\n",
    "avg_metrics = metrics_df[['Accuracy','Precision','Recall','F1-Score','ROC AUC']].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc869326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Começar estrutura HTML\n",
    "html_lines = []\n",
    "\n",
    "html_lines.append(\"<html><head><title>Relatório Comparativo</title>\")\n",
    "html_lines.append(\"<style>\")\n",
    "html_lines.append(\"body {font-family: Arial, sans-serif; margin: 20px; background-color: #f0f8ff; color: #222;}\")\n",
    "html_lines.append(\"h1, h2, h3 { color: #007acc; }\")\n",
    "html_lines.append(\"table {border-collapse: collapse; width: 100%; margin-bottom: 30px; background-color: #ffffff;}\")\n",
    "html_lines.append(\"th, td {border: 1px solid #ddd; padding: 8px; text-align: center;}\")\n",
    "html_lines.append(\"th {background-color: #e6f2ff; cursor: pointer;}\")\n",
    "html_lines.append(\"th:hover {background-color: #d0e7ff;}\")\n",
    "html_lines.append(\"tr:nth-child(even) {background-color: #f9fbfd;}\")\n",
    "html_lines.append(\"tr:hover {background-color: #eef7ff;}\")\n",
    "html_lines.append(\"img {border: 1px solid #ccc; margin: 5px;}\")\n",
    "html_lines.append(\"a { color: #007acc; text-decoration: none; }\")\n",
    "html_lines.append(\"a:hover { text-decoration: underline; }\")\n",
    "html_lines.append(\"button { background-color: #007acc; color: white; border: none; padding: 8px 12px; border-radius: 4px; cursor: pointer; }\")\n",
    "html_lines.append(\"button:hover { background-color: #005f99; }\")\n",
    "html_lines.append(\"</style>\")\n",
    "html_lines.append(\"\"\"\n",
    "<script>\n",
    "function sortTable(n, id) {\n",
    "  var table = document.getElementById(id), rows, switching = true, i, x, y, shouldSwitch, dir = \"asc\", switchcount = 0;\n",
    "  while (switching) {\n",
    "    switching = false;\n",
    "    rows = table.rows;\n",
    "    for (i = 1; i < (rows.length - 1); i++) {\n",
    "      shouldSwitch = false;\n",
    "      x = rows[i].getElementsByTagName(\"TD\")[n];\n",
    "      y = rows[i + 1].getElementsByTagName(\"TD\")[n];\n",
    "      var xVal = isNaN(x.innerHTML) ? x.innerHTML.toLowerCase() : parseFloat(x.innerHTML);\n",
    "      var yVal = isNaN(y.innerHTML) ? y.innerHTML.toLowerCase() : parseFloat(y.innerHTML);\n",
    "      if ((dir === \"asc\" && xVal > yVal) || (dir === \"desc\" && xVal < yVal)) {\n",
    "        shouldSwitch = true; break;\n",
    "      }\n",
    "    }\n",
    "    if (shouldSwitch) {\n",
    "      rows[i].parentNode.insertBefore(rows[i + 1], rows[i]);\n",
    "      switching = true; switchcount++;\n",
    "    } else {\n",
    "      if (switchcount === 0 && dir === \"asc\") {\n",
    "        dir = \"desc\"; switching = true;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "</script>\n",
    "\"\"\")\n",
    "html_lines.append(\"</head><body>\")\n",
    "html_lines.append('<a id=\"inicio\"></a>')\n",
    "html_lines.append(\"<h1>Relatório Comparativo: Modelos de Classificação</h1>\")\n",
    "html_lines.append('<div style=\"margin-bottom: 20px; font-size: 16px;\">')\n",
    "html_lines.append('<b>Ir para:</b> ')\n",
    "html_lines.append('<a href=\"#modelo1\">Baseline</a> | ')\n",
    "html_lines.append('<a href=\"#modelo2\">After Changes</a> | ')\n",
    "html_lines.append('<a href=\"#modelo3\">With SMOTE</a>')\n",
    "html_lines.append('<a href=\"#comparacao\">Comparação por Dataset</a>')\n",
    "html_lines.append('</div>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd0b8b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_lines.append('<h2 id=\"modelo1\">Modelo 1: Logistic Regression (Baseline) <a href=\"#inicio\"> Voltar ao topo</a></h2>')\n",
    "html_lines.append(\"<h3>Médias das Métricas</h3>\")\n",
    "html_lines.append(\"<ul>\")\n",
    "html_lines.append(f\"<li>Accuracy: {avg_metrics['Accuracy']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>Precision: {avg_metrics['Precision']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>Recall: {avg_metrics['Recall']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>F1-Score: {avg_metrics['F1-Score']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>ROC AUC: {avg_metrics['ROC AUC']:.3f}</li>\")\n",
    "html_lines.append(\"</ul>\")\n",
    "\n",
    "html_lines.append('<table id=\"table_baseline\"><tr>')\n",
    "cols = ['Dataset', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC']\n",
    "for i, col in enumerate(cols):\n",
    "    html_lines.append(f'<th onclick=\"sortTable({i}, \\'table_baseline\\')\">{col}</th>')\n",
    "html_lines.append(\"</tr>\")\n",
    "for _, row in metrics_df.iterrows():\n",
    "    html_lines.append(\"<tr>\")\n",
    "    for col in cols:\n",
    "        val = row[col]\n",
    "        html_lines.append(f\"<td>{val:.3f}</td>\" if isinstance(val, float) else f\"<td>{val}</td>\")\n",
    "    html_lines.append(\"</tr>\")\n",
    "html_lines.append(\"</table>\")\n",
    "\n",
    "html_lines.append(\"<h3>Curvas ROC</h3><div style='display: flex; flex-wrap: wrap;'>\")\n",
    "for name, img_b64, auc in roc_images:\n",
    "    html_lines.append(\"<div style='margin:10px; text-align:center;'>\")\n",
    "    html_lines.append(f\"<img src='data:image/png;base64,{img_b64}' width='300'><br>\")\n",
    "    html_lines.append(f\"<span><b>{name}</b><br>AUC = {auc:.3f}</span>\")\n",
    "    html_lines.append(\"</div>\")\n",
    "html_lines.append(\"</div><hr>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07632f2a",
   "metadata": {},
   "source": [
    "We are going to make a HTML report to evaluate our metrics!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b94de0",
   "metadata": {},
   "source": [
    "The overall averages using the Logistic Regression with no modification were:\n",
    "\n",
    "- Accuracy: 0.639\n",
    "\n",
    "- Precision: 0.167\n",
    "\n",
    "- Recall: 0.507\n",
    "\n",
    "- F1-Score: 0.226\n",
    "\n",
    "- ROC AUC: 0.579"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3760c0de",
   "metadata": {},
   "source": [
    "And these results align what we were expecting because the **precision is low** due to the struggle to identify the minority class; **recall is higher** because it's correctly flagging some positives but with many false positives; **F1-score is approximately 0.22** what's in line with a precision-recall trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0be22",
   "metadata": {},
   "source": [
    "Also, we have some datasets where the precision and the recall were 0 because the model predicted only one class due to the strong imbalance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf342dcb",
   "metadata": {},
   "source": [
    "And we have too somes cases with high accuracy and bad recall, a typical illusion of accuracy when the majority class dominates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ea052",
   "metadata": {},
   "source": [
    "Now we can proceed for the next step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16e267",
   "metadata": {},
   "source": [
    "# 6th Step - Model Training & Evaluation: Post‑Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7813c",
   "metadata": {},
   "source": [
    "For this next step we are going to change our initial algorithm by creating a new hiperparameter 'imbalance_penalty' that does:\n",
    "- Helps address class imbalance by **increasing the weight of the minority class** in the loss function.\n",
    "- If set to *>1.0* , the model will **penalize errors on the minority class more heavily**, making it more sensitive to that class.\n",
    "- Applied dynamically based on which class is underrepresented in the training data.\n",
    "- Affects both **loss calculation** and **gradient updates**, guiding the model to perform better on imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b65fe19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLogisticRegression:\n",
    "    def __init__(self, lr=0.01, penalty=None, C=0.01, tolerance=1e-4, max_iters=1000, imbalance_penalty=1.0):\n",
    "        self.lr = lr\n",
    "        self.penalty = penalty    # 'l1', 'l2', or None\n",
    "        self.C = C\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iters = max_iters\n",
    "        self.imbalance_penalty = imbalance_penalty\n",
    "        self.coef_ = None  # Includes intercept as first element\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        N = len(y)\n",
    "        # Determine class counts\n",
    "        N_pos = np.sum(y == 1)\n",
    "        N_neg = np.sum(y == 0)\n",
    "        # Setup class weights manually based on imbalance_penalty\n",
    "        if N_pos == 0 or N_neg == 0:\n",
    "            # If one class is absent, no weighting needed\n",
    "            self.w_pos = 1.0\n",
    "            self.w_neg = 1.0\n",
    "        else:\n",
    "            if self.imbalance_penalty != 1.0:\n",
    "                # Identify minority class\n",
    "                if N_pos < N_neg:\n",
    "                    self.w_pos = self.imbalance_penalty\n",
    "                    self.w_neg = 1.0\n",
    "                elif N_neg < N_pos:\n",
    "                    self.w_pos = 1.0\n",
    "                    self.w_neg = self.imbalance_penalty\n",
    "                else:\n",
    "                    # If classes are balanced, no extra weighting\n",
    "                    self.w_pos = 1.0\n",
    "                    self.w_neg = 1.0\n",
    "            else:\n",
    "                # No imbalance penalty => no weighting\n",
    "                self.w_pos = 1.0\n",
    "                self.w_neg = 1.0\n",
    "\n",
    "        # Add intercept term\n",
    "        X_b = np.hstack([np.ones((N,1)), X])\n",
    "        # Initialize coefficients (bias + weights)\n",
    "        self.coef_ = np.zeros(X_b.shape[1])\n",
    "\n",
    "        prev_cost = float('inf')\n",
    "        for i in range(self.max_iters):\n",
    "            # Compute predictions\n",
    "            z = X_b.dot(self.coef_)\n",
    "            y_pred = self.sigmoid(z)\n",
    "            # Clip predictions to avoid log(0)\n",
    "            eps = 1e-15\n",
    "            y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "            # Compute weighted binary cross-entropy loss\n",
    "            cost = -(1.0 / N) * (\n",
    "                self.w_pos * (y * np.log(y_pred)).sum() +\n",
    "                self.w_neg * ((1 - y) * np.log(1 - y_pred)).sum()\n",
    "            )\n",
    "            # Add regularization penalty (skip intercept at index 0)\n",
    "            if self.penalty == 'l2':\n",
    "                cost += 0.5 * self.C * np.sum(self.coef_[1:]**2)\n",
    "            elif self.penalty == 'l1':\n",
    "                cost += self.C * np.sum(np.abs(self.coef_[1:]))\n",
    "\n",
    "            # Check for convergence\n",
    "            if abs(prev_cost - cost) < self.tolerance:\n",
    "                break\n",
    "            prev_cost = cost\n",
    "\n",
    "            # Compute gradient of weighted loss\n",
    "            error = y_pred - y\n",
    "            weights = np.where(y == 1, self.w_pos, self.w_neg)\n",
    "            gradient = (X_b.T.dot(weights * error)) / N\n",
    "\n",
    "            # Add gradient of penalty (not applying to intercept)\n",
    "            if self.penalty == 'l2':\n",
    "                gradient[1:] += self.C * self.coef_[1:]\n",
    "            elif self.penalty == 'l1':\n",
    "                gradient[1:] += self.C * np.sign(self.coef_[1:])\n",
    "\n",
    "            # Gradient descent update\n",
    "            self.coef_ -= self.lr * gradient\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        N = X.shape[0]\n",
    "        X_b = np.hstack([np.ones((N,1)), X])\n",
    "        return self.sigmoid(X_b.dot(self.coef_))\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cb39416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data and Initialize Structures\n",
    "\n",
    "data_folder = \"class_imbalance_final\"\n",
    "csv_files = sorted(glob.glob(os.path.join(data_folder, \"*.csv\")))\n",
    "\n",
    "# Lists to accumulate results\n",
    "results1 = []  # Will hold dicts of metrics for each dataset\n",
    "roc_images1 = []  # Will hold (dataset_name, base64_png, auc) for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14742915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd162efe1d3e4f6bb4d9127f336afb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Process Each Dataset\n",
    "# For each CSV:\n",
    "# 1. Read data into X (features) and y (binary target).\n",
    "# 2. Repeatedly split (stratified) until both classes present in train and test.\n",
    "# 3. Scale features with StandardScaler (fit on train, transform both).\n",
    "# 4. Train logistic regression.\n",
    "# 5. Compute metrics on test set.\n",
    "# 6. Plot and save ROC curve for this dataset.\n",
    "\n",
    "for file_path in tqdm(csv_files, desc=\"Datasets\"):\n",
    "    dataset_name = os.path.basename(file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Assume the last column is 'target' as preprocessed (0/1)\n",
    "    if 'target' not in df.columns:\n",
    "        # If not labeled, rename last col to 'target'\n",
    "        df = df.rename(columns={df.columns[-1]: 'target'})\n",
    "    X = df.drop(columns=['target']).values\n",
    "    y = df['target'].values\n",
    "\n",
    "    # Stratified split with retries to ensure both classes in train and test\n",
    "    seed = 0\n",
    "    while True:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, stratify=y, random_state=seed\n",
    "        )\n",
    "        # Check class presence\n",
    "        if len(np.unique(y_train)) == 2 and len(np.unique(y_test)) == 2:\n",
    "            break\n",
    "        seed += 1\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Model training\n",
    "    model = LossLogisticRegression()  # using default parameters\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]  # probability of class 1\n",
    "    except:\n",
    "        # Some implementations might use a different method name\n",
    "        y_proba = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results1.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'ROC AUC': auc\n",
    "    })\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "    plt.title(f'ROC Curve: {dataset_name}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot to base64\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    roc_images1.append((dataset_name, img_base64, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2cd6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Metrics and Compute Averages\n",
    "\n",
    "metrics_df1 = pd.DataFrame(results1)\n",
    "# Round metrics for display\n",
    "metrics_df1[['Accuracy','Precision','Recall','F1-Score','ROC AUC']] = metrics_df1[\n",
    "    ['Accuracy','Precision','Recall','F1-Score','ROC AUC']].round(3)\n",
    "\n",
    "# Compute average metrics\n",
    "avg_metrics1 = metrics_df1[['Accuracy','Precision','Recall','F1-Score','ROC AUC']].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1de1c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_lines.append('<h2 id=\"modelo2\">Modelo 2: Logistic Regression (After Changes) <a href=\"#inicio\">🔝 Voltar ao topo</a></h2>')\n",
    "html_lines.append(\"<h3>Médias das Métricas</h3>\")\n",
    "html_lines.append(\"<ul>\")\n",
    "html_lines.append(f\"<li>Accuracy: {avg_metrics1['Accuracy']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>Precision: {avg_metrics1['Precision']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>Recall: {avg_metrics1['Recall']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>F1-Score: {avg_metrics1['F1-Score']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>ROC AUC: {avg_metrics1['ROC AUC']:.3f}</li>\")\n",
    "html_lines.append(\"</ul>\")\n",
    "\n",
    "html_lines.append('<table id=\"table_after\"><tr>')\n",
    "for i, col in enumerate(cols):\n",
    "    html_lines.append(f'<th onclick=\"sortTable({i}, \\'table_after\\')\">{col}</th>')\n",
    "html_lines.append(\"</tr>\")\n",
    "for _, row in metrics_df1.iterrows():\n",
    "    html_lines.append(\"<tr>\")\n",
    "    for col in cols:\n",
    "        val = row[col]\n",
    "        html_lines.append(f\"<td>{val:.3f}</td>\" if isinstance(val, float) else f\"<td>{val}</td>\")\n",
    "    html_lines.append(\"</tr>\")\n",
    "html_lines.append(\"</table>\")\n",
    "\n",
    "html_lines.append(\"<h3>Curvas ROC</h3><div style='display: flex; flex-wrap: wrap;'>\")\n",
    "for name, img_b64, auc in roc_images1:\n",
    "    html_lines.append(\"<div style='margin:10px; text-align:center;'>\")\n",
    "    html_lines.append(f\"<img src='data:image/png;base64,{img_b64}' width='300'><br>\")\n",
    "    html_lines.append(f\"<span><b>{name}</b><br>AUC = {auc:.3f}</span>\")\n",
    "    html_lines.append(\"</div>\")\n",
    "html_lines.append(\"</div><hr>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0cc38",
   "metadata": {},
   "source": [
    "Now we are also going to compare the result using our changed algorithm with SMOTE (Synthetic Minority Over-sampling Technique) to see if the results change!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923aee1c",
   "metadata": {},
   "source": [
    "We are using k=4 neighbours instead of the default k=5 because SMOTE requires at least *k+1* minority class samples, and we have some cases with only 5 minority cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d4493da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0740520453614c98891973497c8d0b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Data and Initialize Structures\n",
    "data_folder = \"class_imbalance_final\"\n",
    "csv_files = sorted(glob.glob(os.path.join(data_folder, \"*.csv\")))\n",
    "\n",
    "results2 = []  # Will hold dicts of metrics for each dataset\n",
    "roc_images2 = []  # Will hold (dataset_name, base64_png, auc) for plots\n",
    "\n",
    "# Process each dataset\n",
    "for file_path in tqdm(csv_files, desc=\"Datasets\"):\n",
    "    dataset_name = os.path.basename(file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Assume the last column is 'target' as preprocessed (0/1)\n",
    "    if 'target' not in df.columns:\n",
    "        df = df.rename(columns={df.columns[-1]: 'target'})\n",
    "\n",
    "    X = df.drop(columns=['target']).values\n",
    "    y = df['target'].values\n",
    "\n",
    "    # Stratified split with retries to ensure both classes in train and test\n",
    "    seed = 0\n",
    "    while True:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, stratify=y, random_state=seed\n",
    "        )\n",
    "        if len(np.unique(y_train)) == 2 and len(np.unique(y_test)) == 2:\n",
    "            break\n",
    "        seed += 1\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    smote = SMOTE(random_state=42, k_neighbors=4)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # Model training\n",
    "    model = LossLogisticRegression()\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test_scaled)\n",
    "    except:\n",
    "        y_proba = y_pred  # fallback if proba isn't supported\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results2.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'ROC AUC': auc\n",
    "    })\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "    plt.title(f'ROC Curve: {dataset_name}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot to base64\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    roc_images2.append((dataset_name, img_base64, auc))\n",
    "\n",
    "    # Convert results list to DataFrame\n",
    "metrics_df2 = pd.DataFrame(results2)\n",
    "\n",
    "# Compute average metrics\n",
    "avg_metrics2= metrics_df2[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46524795",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_lines.append('<h2 id=\"modelo3\">Modelo 3: Logistic Regression (With SMOTE) <a href=\"#inicio\">🔝 Voltar ao topo</a></h2>')\n",
    "html_lines.append(\"<h3>Médias das Métricas</h3>\")\n",
    "html_lines.append(\"<ul>\")\n",
    "html_lines.append(f\"<li>Accuracy: {avg_metrics2['Accuracy']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>Precision: {avg_metrics2['Precision']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>Recall: {avg_metrics2['Recall']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>F1-Score: {avg_metrics2['F1-Score']:.3f}</li>\")\n",
    "html_lines.append(f\"<li>ROC AUC: {avg_metrics2['ROC AUC']:.3f}</li>\")\n",
    "html_lines.append(\"</ul>\")\n",
    "\n",
    "html_lines.append('<table id=\"table_smote\"><tr>')\n",
    "for i, col in enumerate(cols):\n",
    "    html_lines.append(f'<th onclick=\"sortTable({i}, \\'table_smote\\')\">{col}</th>')\n",
    "html_lines.append(\"</tr>\")\n",
    "for _, row in metrics_df2.iterrows():\n",
    "    html_lines.append(\"<tr>\")\n",
    "    for col in cols:\n",
    "        val = row[col]\n",
    "        html_lines.append(f\"<td>{val:.3f}</td>\" if isinstance(val, float) else f\"<td>{val}</td>\")\n",
    "    html_lines.append(\"</tr>\")\n",
    "html_lines.append(\"</table>\")\n",
    "\n",
    "html_lines.append(\"<h3>Curvas ROC</h3><div style='display: flex; flex-wrap: wrap;'>\")\n",
    "for name, img_b64, auc in roc_images2:\n",
    "    html_lines.append(\"<div style='margin:10px; text-align:center;'>\")\n",
    "    html_lines.append(f\"<img src='data:image/png;base64,{img_b64}' width='300'><br>\")\n",
    "    html_lines.append(f\"<span><b>{name}</b><br>AUC = {auc:.3f}</span>\")\n",
    "    html_lines.append(\"</div>\")\n",
    "html_lines.append(\"</div><hr>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68f69ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_lines.append('<hr>')\n",
    "html_lines.append('<a id=\"comparacao\"></a>')\n",
    "html_lines.append('<h2>🔍 Comparação por Dataset</h2>')\n",
    "html_lines.append('<div style=\"margin-top: 20px;\"><a href=\"#inicio\">🔝 Voltar ao topo</a></div>')\n",
    "html_lines.append(\"\"\"\n",
    "<label for=\"datasetSelect\">Escolhe um dataset:</label>\n",
    "<select id=\"datasetSelect\" onchange=\"compararDataset()\">\n",
    "  <option value=\"\">-- Seleciona --</option>\n",
    "</select>\n",
    "\n",
    "<table id=\"comparacaoResultados\" style=\"margin-top:15px; display:none;\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Modelo</th>\n",
    "      <th>Accuracy</th>\n",
    "      <th>Precision</th>\n",
    "      <th>Recall</th>\n",
    "      <th>F1-Score</th>\n",
    "      <th>ROC AUC</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody></tbody>\n",
    "</table>\n",
    "\n",
    "<script>\n",
    "const modelos = [\"Baseline\", \"After Changes\", \"With SMOTE\"];\n",
    "const tabelas = {\n",
    "  \"Baseline\": document.getElementById(\"table_baseline\"),\n",
    "  \"After Changes\": document.getElementById(\"table_after\"),\n",
    "  \"With SMOTE\": document.getElementById(\"table_smote\")\n",
    "};\n",
    "\n",
    "\n",
    "// Recolher todos os nomes de dataset existentes\n",
    "const nomesDatasets = new Set();\n",
    "for (const modelo in tabelas) {\n",
    "  const linhas = tabelas[modelo].querySelectorAll(\"tbody tr\");\n",
    "  for (const linha of linhas) {\n",
    "    const nome = linha.children[0].textContent.trim();\n",
    "    nomesDatasets.add(nome);\n",
    "  }\n",
    "}\n",
    "\n",
    "// Preencher o dropdown\n",
    "const select = document.getElementById(\"datasetSelect\");\n",
    "[...nomesDatasets].sort().forEach(nome => {\n",
    "  const option = document.createElement(\"option\");\n",
    "  option.value = nome;\n",
    "  option.textContent = nome;\n",
    "  select.appendChild(option);\n",
    "});\n",
    "\n",
    "function compararDataset() {\n",
    "  const ds = select.value;\n",
    "  const tabela = document.getElementById(\"comparacaoResultados\");\n",
    "  const tbody = tabela.querySelector(\"tbody\");\n",
    "  tbody.innerHTML = \"\";\n",
    "\n",
    "  if (!ds) {\n",
    "    tabela.style.display = \"none\";\n",
    "    return;\n",
    "  }\n",
    "\n",
    "  for (const modelo in tabelas) {\n",
    "    const linhas = tabelas[modelo].querySelectorAll(\"tbody tr\");\n",
    "    for (const linha of linhas) {\n",
    "      if (linha.children[0].textContent.trim() === ds) {\n",
    "        const novaLinha = document.createElement(\"tr\");\n",
    "        novaLinha.innerHTML = `<td>${modelo}</td>` +\n",
    "          [...linha.children].slice(1).map(td => `<td>${td.textContent}</td>`).join(\"\");\n",
    "        tbody.appendChild(novaLinha);\n",
    "        break;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  tabela.style.display = \"table\";\n",
    "}\n",
    "</script>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c9fffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_lines.append(\"</body></html>\")\n",
    "\n",
    "with open(\"relatorio_comparativo_final.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(html_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4e3ab",
   "metadata": {},
   "source": [
    "We observed that adding SMOTE to a cost-sensitive logistic regression led to modest improvements, particularly in AUC but overall the gains were incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42353d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_lines = []\n",
    "\n",
    "# Cabeçalho com CSS e JavaScript\n",
    "html_lines.append(\"<html><head><title>Relatório Comparativo</title>\")\n",
    "html_lines.append(\"<style>\")\n",
    "html_lines.append(\"body {font-family: Arial, sans-serif; margin: 20px; background-color: #f0f8ff; color: #222;}\")\n",
    "html_lines.append(\"h1, h2, h3 { color: #007acc; }\")\n",
    "html_lines.append(\"table {border-collapse: collapse; width: 100%; margin-bottom: 30px; background-color: #ffffff;}\")\n",
    "html_lines.append(\"th, td {border: 1px solid #ddd; padding: 8px; text-align: center;}\")\n",
    "html_lines.append(\"th {background-color: #e6f2ff; cursor: pointer;}\")\n",
    "html_lines.append(\"th:hover {background-color: #d0e7ff;}\")\n",
    "html_lines.append(\"tr:nth-child(even) {background-color: #f9fbfd;}\")\n",
    "html_lines.append(\"tr:hover {background-color: #eef7ff;}\")\n",
    "html_lines.append(\"img {border: 1px solid #ccc; margin: 5px;}\")\n",
    "html_lines.append(\"a { color: #007acc; text-decoration: none; }\")\n",
    "html_lines.append(\"a:hover { text-decoration: underline; }\")\n",
    "html_lines.append(\"button { background-color: #007acc; color: white; border: none; padding: 8px 12px; border-radius: 4px; cursor: pointer; }\")\n",
    "html_lines.append(\"button:hover { background-color: #005f99; }\")\n",
    "html_lines.append(\"</style>\")\n",
    "html_lines.append(\"\"\"\n",
    "<script>\n",
    "function sortTable(n, id) {\n",
    "  var table = document.getElementById(id), rows, switching = true, i, x, y, shouldSwitch, dir = \"asc\", switchcount = 0;\n",
    "  while (switching) {\n",
    "    switching = false;\n",
    "    rows = table.rows;\n",
    "    for (i = 1; i < (rows.length - 1); i++) {\n",
    "      shouldSwitch = false;\n",
    "      x = rows[i].getElementsByTagName(\"TD\")[n];\n",
    "      y = rows[i + 1].getElementsByTagName(\"TD\")[n];\n",
    "      var xVal = isNaN(x.innerHTML) ? x.innerHTML.toLowerCase() : parseFloat(x.innerHTML);\n",
    "      var yVal = isNaN(y.innerHTML) ? y.innerHTML.toLowerCase() : parseFloat(y.innerHTML);\n",
    "      if ((dir === \"asc\" && xVal > yVal) || (dir === \"desc\" && xVal < yVal)) {\n",
    "        shouldSwitch = true; break;\n",
    "      }\n",
    "    }\n",
    "    if (shouldSwitch) {\n",
    "      rows[i].parentNode.insertBefore(rows[i + 1], rows[i]);\n",
    "      switching = true; switchcount++;\n",
    "    } else {\n",
    "      if (switchcount === 0 && dir === \"asc\") {\n",
    "        dir = \"desc\"; switching = true;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "</script>\n",
    "\"\"\")\n",
    "html_lines.append(\"</head><body>\")\n",
    "html_lines.append(\"<h1>Relatório Comparativo: Modelos de Classificação</h1>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e745891",
   "metadata": {},
   "source": [
    "# 7th Step - Creating the HTML for results viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c022a",
   "metadata": {},
   "source": [
    "Now that we have all the results we are going to create two HTML files for comparison of results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c82e2",
   "metadata": {},
   "source": [
    "We are going to be able to compare the results through models and through datasets as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dce2c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "steelblue"
         },
         "name": "Baseline",
         "type": "bar",
         "x": [
          "Accuracy",
          "Precision",
          "Recall",
          "F1-Score",
          "ROC AUC"
         ],
         "xaxis": "x",
         "y": [
          0.619,
          0.092,
          0.448,
          0.153,
          0.541
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "orange"
         },
         "name": "After Changes",
         "type": "bar",
         "x": [
          "Accuracy",
          "Precision",
          "Recall",
          "F1-Score",
          "ROC AUC"
         ],
         "xaxis": "x",
         "y": [
          0.942,
          1,
          0.241,
          0.389,
          0.621
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "green"
         },
         "name": "Changes + SMOTE",
         "type": "bar",
         "x": [
          "Accuracy",
          "Precision",
          "Recall",
          "F1-Score",
          "ROC AUC"
         ],
         "xaxis": "x",
         "y": [
          0.7464664310954063,
          0.20930232558139536,
          0.8275862068965517,
          0.33410672853828305,
          0.9052631578947369
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "steelblue"
         },
         "mode": "lines",
         "name": "Baseline ROC",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "xaxis": "x2",
         "y": [
          0,
          1
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "After Changes ROC",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "xaxis": "x2",
         "y": [
          0.1,
          0.9
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "green",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "Changes+SMOTE ROC",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "xaxis": "x2",
         "y": [
          0.05,
          0.95
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Metrics Comparison",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "ROC Curve",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "legend": {
         "title": {
          "text": "Model"
         }
        },
        "margin": {
         "t": 100
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Comparison: Dataset = dataset_1000_hypothyroid.csv"
        },
        "updatemenus": [
         {
          "active": 0,
          "buttons": [
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.619,
                0.092,
                0.448,
                0.153,
                0.541
               ],
               [
                0.942,
                1,
                0.241,
                0.389,
                0.621
               ],
               [
                0.7464664310954063,
                0.20930232558139536,
                0.8275862068965517,
                0.33410672853828305,
                0.9052631578947369
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1000_hypothyroid.csv"
             }
            ],
            "label": "dataset_1000_hypothyroid.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.527,
                0.101,
                0.443,
                0.165,
                0.49
               ],
               [
                0.894,
                0.438,
                0.03,
                0.055,
                0.513
               ],
               [
                0.6495992876224399,
                0.23039215686274508,
                0.9915611814345991,
                0.3739061256961018,
                0.8404689446016133
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1002_ipums_la_98-small.csv"
             }
            ],
            "label": "dataset_1002_ipums_la_98-small.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.7,
                0.35,
                0.933,
                0.509,
                0.793
               ],
               [
                1,
                1,
                1,
                1,
                1
               ],
               [
                0.9888888888888889,
                0.9375,
                1,
                0.967741935483871,
                1
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1004_synthetic_control.csv"
             }
            ],
            "label": "dataset_1004_synthetic_control.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.929,
                0,
                0,
                0,
                0.5
               ],
               [
                0.929,
                0,
                0,
                0,
                0.5
               ],
               [
                0.6190476190476191,
                0.06666666666666667,
                0.3333333333333333,
                0.1111111111111111,
                0.6666666666666666
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1013_analcatdata_challenger.csv"
             }
            ],
            "label": "dataset_1013_analcatdata_challenger.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.433,
                0.184,
                0.553,
                0.277,
                0.479
               ],
               [
                0.804,
                0,
                0,
                0,
                0.5
               ],
               [
                0.5291666666666667,
                0.21551724137931033,
                0.5319148936170213,
                0.3067484662576687,
                0.5063940028662771
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1014_analcatdata_dmft.csv"
             }
            ],
            "label": "dataset_1014_analcatdata_dmft.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.613,
                0.151,
                0.704,
                0.248,
                0.654
               ],
               [
                0.946,
                1,
                0.407,
                0.579,
                0.704
               ],
               [
                0.8653198653198653,
                0.40298507462686567,
                1,
                0.5744680851063829,
                0.9755829903978053
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1016_vowel.csv"
             }
            ],
            "label": "dataset_1016_vowel.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.604,
                0.047,
                0.271,
                0.08,
                0.449
               ],
               [
                0.938,
                0.778,
                0.041,
                0.078,
                0.52
               ],
               [
                0.6507159005275056,
                0.1505078485687904,
                0.9588235294117647,
                0.26017557861133284,
                0.8814814814814814
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1018_ipums_la_99-small.csv"
             }
            ],
            "label": "dataset_1018_ipums_la_99-small.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.567,
                0.173,
                0.883,
                0.29,
                0.707
               ],
               [
                0.995,
                0.983,
                0.967,
                0.975,
                0.982
               ],
               [
                0.9316666666666666,
                0.594059405940594,
                1,
                0.7453416149068323,
                0.999783950617284
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1020_mfeat-karhunen.csv"
             }
            ],
            "label": "dataset_1020_mfeat-karhunen.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.859,
                0.365,
                0.506,
                0.424,
                0.703
               ],
               [
                0.938,
                0.924,
                0.435,
                0.591,
                0.715
               ],
               [
                0.8800243605359318,
                0.4553846153846154,
                0.8809523809523809,
                0.6004056795131846,
                0.9394242262712412
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1021_page-blocks.csv"
             }
            ],
            "label": "dataset_1021_page-blocks.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.562,
                0.139,
                0.65,
                0.229,
                0.601
               ],
               [
                0.99,
                0.909,
                1,
                0.952,
                0.994
               ],
               [
                0.9183333333333333,
                0.5504587155963303,
                1,
                0.7100591715976332,
                0.9998456790123458
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1022_mfeat-pixel.csv"
             }
            ],
            "label": "dataset_1022_mfeat-pixel.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.537,
                0.124,
                0.393,
                0.188,
                0.476
               ],
               [
                0.937,
                0.778,
                0.75,
                0.764,
                0.858
               ],
               [
                0.8926829268292683,
                0.5625,
                0.9642857142857143,
                0.7105263157894737,
                0.9804277643260695
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1023_soybean.csv"
             }
            ],
            "label": "dataset_1023_soybean.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.564,
                0.042,
                0.511,
                0.077,
                0.539
               ],
               [
                0.965,
                0.526,
                0.222,
                0.312,
                0.607
               ],
               [
                0.8699763593380615,
                0.16666666666666666,
                0.6666666666666666,
                0.26666666666666666,
                0.7698075526506898
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1039_hiva_agnostic.csv"
             }
            ],
            "label": "dataset_1039_hiva_agnostic.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.682,
                0.125,
                1,
                0.222,
                0.833
               ],
               [
                0.955,
                0.5,
                0.5,
                0.5,
                0.738
               ],
               [
                0.8409090909090909,
                0.14285714285714285,
                0.5,
                0.22222222222222224,
                0.9285714285714286
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1045_kc1-top5.csv"
             }
            ],
            "label": "dataset_1045_kc1-top5.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.678,
                0.107,
                0.226,
                0.145,
                0.483
               ],
               [
                0.897,
                0.75,
                0.226,
                0.348,
                0.608
               ],
               [
                0.7328767123287672,
                0.2948717948717949,
                0.8679245283018868,
                0.4401913875598086,
                0.8593972065670179
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1049_pc4.csv"
             }
            ],
            "label": "dataset_1049_pc4.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.761,
                0.128,
                0.229,
                0.164,
                0.526
               ],
               [
                0.896,
                0.4,
                0.042,
                0.075,
                0.517
               ],
               [
                0.7014925373134329,
                0.2261904761904762,
                0.7916666666666666,
                0.35185185185185186,
                0.8253414489311164
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1050_pc3.csv"
             }
            ],
            "label": "dataset_1050_pc3.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.716,
                0.001,
                0.05,
                0.002,
                0.385
               ],
               [
                0.993,
                0,
                0,
                0,
                0.5
               ],
               [
                0.8253521126760563,
                0.029644268774703556,
                0.75,
                0.05703422053231939,
                0.9270478723404255
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1056_mc1.csv"
             }
            ],
            "label": "dataset_1056_mc1.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.568,
                0,
                0,
                0,
                0.309
               ],
               [
                0.919,
                0,
                0,
                0,
                0.5
               ],
               [
                0.6216216216216216,
                0.13333333333333333,
                0.6666666666666666,
                0.2222222222222222,
                0.8431372549019608
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1059_ar1.csv"
             }
            ],
            "label": "dataset_1059_ar1.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.636,
                0.286,
                0.667,
                0.4,
                0.648
               ],
               [
                0.848,
                0.6,
                0.5,
                0.545,
                0.713
               ],
               [
                0.6060606060606061,
                0.26666666666666666,
                0.6666666666666666,
                0.3809523809523809,
                0.7901234567901234
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1061_ar4.csv"
             }
            ],
            "label": "dataset_1061_ar4.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.871,
                0.667,
                0.4,
                0.5,
                0.681
               ],
               [
                0.871,
                1,
                0.2,
                0.333,
                0.6
               ],
               [
                0.6129032258064516,
                0.18181818181818182,
                0.4,
                0.25000000000000006,
                0.5846153846153846
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1064_ar6.csv"
             }
            ],
            "label": "dataset_1064_ar6.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.63,
                0.135,
                0.538,
                0.215,
                0.589
               ],
               [
                0.913,
                1,
                0.077,
                0.143,
                0.538
               ],
               [
                0.7463768115942029,
                0.23809523809523808,
                0.7692307692307693,
                0.36363636363636365,
                0.844923076923077
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_1065_kc3.csv"
             }
            ],
            "label": "dataset_1065_kc3.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.465,
                0.057,
                0.75,
                0.107,
                0.601
               ],
               [
                0.965,
                1,
                0.167,
                0.286,
                0.583
               ],
               [
                0.8617021276595744,
                0.18604651162790697,
                0.6666666666666666,
                0.2909090909090909,
                0.9015432098765432
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_311_oil_spill.csv"
             }
            ],
            "label": "dataset_311_oil_spill.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.548,
                0.212,
                0.566,
                0.309,
                0.555
               ],
               [
                0.943,
                0.844,
                0.837,
                0.84,
                0.902
               ],
               [
                0.8603042876901799,
                0.5636363636363636,
                0.9612403100775194,
                0.7106017191977076,
                0.9660820087176677
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_312_scene.csv"
             }
            ],
            "label": "dataset_312_scene.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.649,
                0.023,
                0.6,
                0.045,
                0.625
               ],
               [
                0.986,
                0,
                0,
                0,
                0.5
               ],
               [
                0.8140495867768595,
                0.06293706293706294,
                0.9,
                0.11764705882352942,
                0.910195530726257
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_316_yeast_ml8.csv"
             }
            ],
            "label": "dataset_316_yeast_ml8.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.723,
                0.045,
                0.174,
                0.071,
                0.466
               ],
               [
                0.94,
                0.6,
                0.043,
                0.081,
                0.521
               ],
               [
                0.784452296819788,
                0.20930232558139536,
                0.9130434782608695,
                0.34054054054054056,
                0.9277816406942342
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_38_sick.csv"
             }
            ],
            "label": "dataset_38_sick.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.575,
                0.15,
                1,
                0.261,
                0.77
               ],
               [
                0.95,
                1,
                0.333,
                0.5,
                0.667
               ],
               [
                0.8375,
                0.3157894736842105,
                1,
                0.4799999999999999,
                1
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_450_analcatdata_lawsuit.csv"
             }
            ],
            "label": "dataset_450_analcatdata_lawsuit.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.667,
                0.238,
                0.714,
                0.357,
                0.687
               ],
               [
                0.889,
                0.667,
                0.286,
                0.4,
                0.632
               ],
               [
                0.7592592592592593,
                0.3125,
                0.7142857142857143,
                0.43478260869565216,
                0.7264437689969605
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_463_backache.csv"
             }
            ],
            "label": "dataset_463_backache.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.528,
                0.136,
                0.688,
                0.227,
                0.599
               ],
               [
                0.881,
                0,
                0,
                0,
                0.49
               ],
               [
                0.6289308176100629,
                0.15873015873015872,
                0.625,
                0.2531645569620253,
                0.7460664335664335
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_757_meta.csv"
             }
            ],
            "label": "dataset_757_meta.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.585,
                0.1,
                0.312,
                0.152,
                0.467
               ],
               [
                0.919,
                0.857,
                0.375,
                0.522,
                0.683
               ],
               [
                0.7481481481481481,
                0.3125,
                0.9375,
                0.46875,
                0.9359243697478992
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_764_analcatdata_apnea3.csv"
             }
            ],
            "label": "dataset_764_analcatdata_apnea3.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.615,
                0.14,
                0.368,
                0.203,
                0.511
               ],
               [
                0.93,
                1,
                0.474,
                0.643,
                0.737
               ],
               [
                0.9230769230769231,
                0.6666666666666666,
                0.8421052631578947,
                0.744186046511628,
                0.8781833616298811
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_765_analcatdata_apnea2.csv"
             }
            ],
            "label": "dataset_765_analcatdata_apnea2.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.594,
                0,
                0,
                0,
                0.34
               ],
               [
                0.909,
                0.727,
                0.444,
                0.552,
                0.71
               ],
               [
                0.6433566433566433,
                0.2537313432835821,
                0.9444444444444444,
                0.39999999999999997,
                0.9195555555555556
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_767_analcatdata_apnea1.csv"
             }
            ],
            "label": "dataset_767_analcatdata_apnea1.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.433,
                0.105,
                1,
                0.19,
                0.696
               ],
               [
                0.933,
                0,
                0,
                0,
                0.5
               ],
               [
                0.43333333333333335,
                0.10526315789473684,
                1,
                0.1904761904761905,
                0.6964285714285714
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_865_analcatdata_neavote.csv"
             }
            ],
            "label": "dataset_865_analcatdata_neavote.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.718,
                0.3,
                0.429,
                0.353,
                0.605
               ],
               [
                0.872,
                0.667,
                0.571,
                0.615,
                0.754
               ],
               [
                0.8461538461538461,
                0.5714285714285714,
                0.5714285714285714,
                0.5714285714285714,
                0.7901785714285714
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_867_visualizing_livestock.csv"
             }
            ],
            "label": "dataset_867_visualizing_livestock.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.667,
                0.25,
                0.333,
                0.286,
                0.542
               ],
               [
                0.933,
                0.833,
                0.833,
                0.833,
                0.896
               ],
               [
                0.8666666666666667,
                0.6,
                1,
                0.7499999999999999,
                0.9652777777777778
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_875_analcatdata_chlamydia.csv"
             }
            ],
            "label": "dataset_875_analcatdata_chlamydia.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.56,
                0.189,
                0.583,
                0.286,
                0.569
               ],
               [
                0.881,
                1,
                0.208,
                0.345,
                0.604
               ],
               [
                0.7295597484276729,
                0.32727272727272727,
                0.75,
                0.4556962025316456,
                0.8185185185185184
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_940_water-treatment.csv"
             }
            ],
            "label": "dataset_940_water-treatment.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.958,
                0,
                0,
                0,
                0.5
               ],
               [
                0.976,
                1,
                0.429,
                0.6,
                0.714
               ],
               [
                0.7142857142857143,
                0.11320754716981132,
                0.8571428571428571,
                0.2,
                0.8411712511091393
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_947_arsenic-male-bladder.csv"
             }
            ],
            "label": "dataset_947_arsenic-male-bladder.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.613,
                0.127,
                0.292,
                0.177,
                0.479
               ],
               [
                0.869,
                0.75,
                0.125,
                0.214,
                0.559
               ],
               [
                0.6488095238095238,
                0.27848101265822783,
                0.9166666666666666,
                0.42718446601941745,
                0.8139467592592593
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_949_arsenic-female-bladder.csv"
             }
            ],
            "label": "dataset_949_arsenic-female-bladder.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.988,
                1,
                0.667,
                0.8,
                0.833
               ],
               [
                0.982,
                1,
                0.5,
                0.667,
                0.75
               ],
               [
                0.8809523809523809,
                0.18181818181818182,
                0.6666666666666666,
                0.28571428571428575,
                0.8323045267489712
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_950_arsenic-female-lung.csv"
             }
            ],
            "label": "dataset_950_arsenic-female-lung.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.458,
                0,
                0,
                0,
                0.235
               ],
               [
                0.994,
                1,
                0.75,
                0.857,
                0.875
               ],
               [
                1,
                1,
                1,
                1,
                1
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_951_arsenic-male-lung.csv"
             }
            ],
            "label": "dataset_951_arsenic-male-lung.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.7,
                0.218,
                0.706,
                0.333,
                0.703
               ],
               [
                0.962,
                1,
                0.647,
                0.786,
                0.824
               ],
               [
                0.80625,
                0.3541666666666667,
                1,
                0.5230769230769231,
                0.9831345125462773
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_954_spectrometer.csv"
             }
            ],
            "label": "dataset_954_spectrometer.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.587,
                0.229,
                0.798,
                0.356,
                0.675
               ],
               [
                0.916,
                0.918,
                0.455,
                0.608,
                0.724
               ],
               [
                0.8181818181818182,
                0.44,
                1,
                0.6111111111111112,
                0.9887086351732817
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_958_segment.csv"
             }
            ],
            "label": "dataset_958_segment.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.742,
                0,
                0,
                0,
                0.412
               ],
               [
                0.998,
                1,
                0.983,
                0.992,
                0.992
               ],
               [
                0.935,
                0.6082474226804123,
                0.9833333333333333,
                0.751592356687898,
                0.9888271604938271
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_962_mfeat-morphological.csv"
             }
            ],
            "label": "dataset_962_mfeat-morphological.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.622,
                0.138,
                0.595,
                0.224,
                0.61
               ],
               [
                0.96,
                0.889,
                0.649,
                0.75,
                0.82
               ],
               [
                0.8159203980099502,
                0.3238095238095238,
                0.918918918918919,
                0.47887323943661975,
                0.9658644946316179
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_966_analcatdata_halloffame.csv"
             }
            ],
            "label": "dataset_966_analcatdata_halloffame.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.555,
                0.163,
                0.5,
                0.246,
                0.532
               ],
               [
                0.882,
                0.714,
                0.312,
                0.435,
                0.646
               ],
               [
                0.8272727272727273,
                0.45714285714285713,
                1,
                0.6274509803921569,
                0.9488031914893617
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_968_analcatdata_birthday.csv"
             }
            ],
            "label": "dataset_968_analcatdata_birthday.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.547,
                0.156,
                0.8,
                0.261,
                0.659
               ],
               [
                0.997,
                0.968,
                1,
                0.984,
                0.998
               ],
               [
                0.9666666666666667,
                0.75,
                1,
                0.8571428571428571,
                0.9999691358024692
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_971_mfeat-fourier.csv"
             }
            ],
            "label": "dataset_971_mfeat-fourier.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.645,
                0.268,
                0.688,
                0.386,
                0.663
               ],
               [
                0.95,
                0.888,
                0.789,
                0.836,
                0.885
               ],
               [
                0.867514218802275,
                0.5502283105022832,
                0.9958677685950413,
                0.7088235294117647,
                0.9864617871694628
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_976_JapaneseVowels.csv"
             }
            ],
            "label": "dataset_976_JapaneseVowels.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.595,
                0.192,
                0.95,
                0.319,
                0.753
               ],
               [
                0.987,
                0.882,
                1,
                0.938,
                0.993
               ],
               [
                0.935,
                0.6060606060606061,
                1,
                0.7547169811320755,
                0.999753086419753
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_978_mfeat-factors.csv"
             }
            ],
            "label": "dataset_978_mfeat-factors.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.634,
                0.178,
                0.715,
                0.285,
                0.67
               ],
               [
                0.982,
                0.938,
                0.884,
                0.91,
                0.939
               ],
               [
                0.8973902728351127,
                0.4984894259818731,
                0.9593023255813954,
                0.6560636182902584,
                0.9900195078492212
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_980_optdigits.csv"
             }
            ],
            "label": "dataset_980_optdigits.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.791,
                0.158,
                0.3,
                0.207,
                0.57
               ],
               [
                0.909,
                0,
                0,
                0,
                0.5
               ],
               [
                0.45454545454545453,
                0.0967741935483871,
                0.6,
                0.16666666666666666,
                0.491
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_984_analcatdata_draft.csv"
             }
            ],
            "label": "dataset_984_analcatdata_draft.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.46,
                0.139,
                0.458,
                0.214,
                0.459
               ],
               [
                0.9,
                0.667,
                0.75,
                0.706,
                0.839
               ],
               [
                0.7933333333333333,
                0.4339622641509434,
                0.9583333333333334,
                0.5974025974025975,
                0.9520502645502645
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_987_collins.csv"
             }
            ],
            "label": "dataset_987_collins.csv",
            "method": "update"
           },
           {
            "args": [
             {
              "x": [
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                "Accuracy",
                "Precision",
                "Recall",
                "F1-Score",
                "ROC AUC"
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ],
               [
                0,
                1
               ]
              ],
              "y": [
               [
                0.675,
                0.229,
                0.95,
                0.369,
                0.797
               ],
               [
                0.995,
                0.967,
                0.983,
                0.975,
                0.99
               ],
               [
                0.925,
                0.5714285714285714,
                1,
                0.7272727272727273,
                0.9996913580246913
               ],
               [
                0,
                1
               ],
               [
                0.1,
                0.9
               ],
               [
                0.05,
                0.95
               ]
              ]
             },
             {
              "title": "Model Comparison: Dataset = dataset_995_mfeat-zernike.csv"
             }
            ],
            "label": "dataset_995_mfeat-zernike.csv",
            "method": "update"
           }
          ],
          "x": 0.5,
          "xanchor": "center",
          "y": 1.15,
          "yanchor": "top"
         }
        ],
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Score"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "True Positive Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume these DataFrames exist from earlier steps:\n",
    "# metrics_df  -> Baseline metrics (indexed by 'Dataset')\n",
    "# metrics_df1 -> After Changes metrics (indexed by 'Dataset')\n",
    "# metrics_df2 -> Changes + SMOTE metrics (indexed by 'Dataset')\n",
    "\n",
    "# List of metric names (as in the notebook)\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC']\n",
    "# List of models and colors\n",
    "models = ['Baseline', 'After Changes', 'Changes + SMOTE']\n",
    "colors = {'Baseline': 'steelblue', \n",
    "          'After Changes': 'orange', \n",
    "          'Changes + SMOTE': 'green'}\n",
    "\n",
    "# Ensure 'Dataset' is index (if not already)\n",
    "metrics_df = metrics_df.set_index('Dataset')\n",
    "metrics_df1 = metrics_df1.set_index('Dataset')\n",
    "metrics_df2 = metrics_df2.set_index('Dataset')\n",
    "\n",
    "# All dataset names to include in dropdown\n",
    "dataset_names = list(metrics_df.index)\n",
    "\n",
    "# Create subplots: 1 row x 2 cols\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Metrics Comparison', 'ROC Curve'))\n",
    "\n",
    "# Initial dataset (first one)\n",
    "initial_ds = dataset_names[0]\n",
    "# Extract initial y-values for bars\n",
    "y_base = [metrics_df.loc[initial_ds, m]    for m in metrics]\n",
    "y_after = [metrics_df1.loc[initial_ds, m]  for m in metrics]\n",
    "y_smote = [metrics_df2.loc[initial_ds, m]  for m in metrics]\n",
    "\n",
    "# Add bar chart traces (one trace per model)\n",
    "fig.add_trace(go.Bar(name='Baseline', x=metrics, y=y_base, marker_color=colors['Baseline']), row=1, col=1)\n",
    "fig.add_trace(go.Bar(name='After Changes', x=metrics, y=y_after, marker_color=colors['After Changes']), row=1, col=1)\n",
    "fig.add_trace(go.Bar(name='Changes + SMOTE', x=metrics, y=y_smote, marker_color=colors['Changes + SMOTE']), row=1, col=1)\n",
    "\n",
    "# Add ROC curve traces for initial dataset (dummy example curves here)\n",
    "# In practice, replace x= and y= with the actual fpr/tpr arrays for each model.\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Baseline ROC', \n",
    "                         line=dict(color=colors['Baseline'])), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0.1,0.9], mode='lines', name='After Changes ROC', \n",
    "                         line=dict(color=colors['After Changes'])), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0.05,0.95], mode='lines', name='Changes+SMOTE ROC', \n",
    "                         line=dict(color=colors['Changes + SMOTE'], dash='dash')), row=1, col=2)\n",
    "\n",
    "# Update layout titles\n",
    "fig.update_layout(title_text=f\"Model Comparison: Dataset = {initial_ds}\", \n",
    "                  showlegend=True, \n",
    "                  legend_title_text='Model',\n",
    "                  yaxis=dict(title='Score'), \n",
    "                  yaxis2=dict(title='True Positive Rate'),\n",
    "                  xaxis2=dict(title='False Positive Rate'))\n",
    "\n",
    "# Prepare dropdown buttons (one per dataset)\n",
    "buttons = []\n",
    "for ds in dataset_names:\n",
    "    # New bar heights for this dataset\n",
    "    yb = [metrics_df.loc[ds, m]    for m in metrics]\n",
    "    ya = [metrics_df1.loc[ds, m]   for m in metrics]\n",
    "    ys = [metrics_df2.loc[ds, m]   for m in metrics]\n",
    "    # (Here we would also compute the new ROC curves if we have data)\n",
    "    # For example, new ROC points could be precomputed fpr/ tpr arrays:\n",
    "    # fpr_base, tpr_base = compute_roc('Baseline', ds)\n",
    "    # etc. As placeholders, we'll keep the same line segments.\n",
    "    new_y = [yb, ya, ys,  # bar traces update\n",
    "             [0,1], [0.1,0.9], [0.05,0.95]]  # ROC traces (dummy here)\n",
    "    buttons.append(dict(label=ds,\n",
    "                        method='update',\n",
    "                        args=[{\n",
    "                            'y': new_y,\n",
    "                            'x': [metrics, metrics, metrics, [0,1], [0,1], [0,1]]\n",
    "                        }, {\n",
    "                            'title': f\"Model Comparison: Dataset = {ds}\"\n",
    "                        }]))\n",
    "# Add dropdown to layout\n",
    "fig.update_layout(\n",
    "    updatemenus=[dict(active=0, buttons=buttons, \n",
    "                      x=0.5, xanchor='center', y=1.15, yanchor='top')],\n",
    "    margin=dict(t=100)  # make space for dropdown\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad84f6c",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb7964",
   "metadata": {},
   "source": [
    "| Metric    | Baseline | After Changes | Changes + SMOTE |\n",
    "| --------- | -------- | ------------- | --------------- |\n",
    "| Accuracy  | 0.639    | 0.935         | 0.785           |\n",
    "| Precision | 0.167    | 0.707         | 0.359           |\n",
    "| Recall    | 0.507    | 0.429         | 0.845           |\n",
    "| F1-Score  | 0.226    | 0.490         | 0.477           |\n",
    "| ROC AUC   | 0.579    | 0.709         | 0.881           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bb3ba",
   "metadata": {},
   "source": [
    "The model changes led to significant improvements in accuracy, precision, and F1-Score, although recall slightly decreased. After applying SMOTE, recall increased substantially (to 0.845), and overall performance improved (ROC AUC of 0.881), despite a drop in precision. Therefore, the SMOTE-enhanced model is more suitable when identifying positive cases is critical, while the model without SMOTE is preferable when higher precision is required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
